====================================
 RL All Scenarios Job Started
 Job ID: 5971642
 Node: g32
 Time: Wed Dec 17 21:02:00 EST 2025
====================================

[CONFIG] Scenario Set: s1
[CONFIG] Episodes per scenario: 200
[CONFIG] Train: true
[CONFIG] Evaluate: true
[CONFIG] Plot: true

[SETUP] Loading modules...
[SETUP] Loaded modules:

Currently Loaded Modules:
  1) CCconfig            6) ucx/1.14.1            11) flexiblas/3.3.1
  2) gentoo/2023   (S)   7) libfabric/1.18.0      12) imkl/2023.2.0   (math)
  3) gcccore/.12.3 (H)   8) pmix/4.2.4            13) StdEnv/2023     (S)
  4) gcc/12.3      (t)   9) ucc/1.2.0             14) python/3.13.2   (t)
  5) hwloc/2.9.1        10) openmpi/4.1.5    (m)

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 


[SETUP] Working directory: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL

[SETUP] Activating virtual environment...
[SETUP] ✓ Virtual environment activated

=====================================
PYTHON & PYTORCH DIAGNOSTICS
=====================================
Python version: Python 3.13.2
Python path: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/bin/python
Pip version: pip 24.3.1 from /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/lib/python3.13/site-packages/pip (python 3.13)

[PYTORCH] Testing PyTorch installation...
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
GPU count: 1
GPU name: NVIDIA H100 80GB HBM3 MIG 1g.10gb

=====================================
ENVIRONMENT VARIABLES
=====================================
SLURM_JOB_ID: 5971642
SLURM_JOB_NAME: rl_all_s1
SLURM_NODELIST: g32
SLURM_CPUS_PER_TASK: 4
SLURM_MEM_PER_NODE: 32768
CUDA_VISIBLE_DEVICES: MIG-733affd1-f6a6-5ed0-81c7-d56d63352f03

[SETUP] Setting CPU threading limits...
[SETUP] OMP_NUM_THREADS=4
[SETUP] MKL_NUM_THREADS=4

=====================================
GPU DIAGNOSTICS (nvidia-smi)
=====================================
Wed Dec 17 21:02:08 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                   On |
| N/A   43C    P0            369W /  700W |   25928MiB /  81559MiB |     N/A      Default |
|                                         |                        |              Enabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| MIG devices:                                                                            |
+------------------+----------------------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |              Shared Memory-Usage |        Vol|        Shared         |
|      ID  ID  Dev |                Shared BAR1-Usage | SM     Unc| CE ENC  DEC  OFA  JPG |
|                  |                                  |        ECC|                       |
|==================+==================================+===========+=======================|
|  0   10   0   0  |              15MiB /  9984MiB    | 16      0 |  1   0    1    0    1 |
|                  |               0MiB /  6185MiB    |           |                       |
+------------------+----------------------------------+-----------+-----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

[GPU] ✓ GPU detected

=====================================
PYTHON PACKAGE VERIFICATION
=====================================
[PACKAGES] Checking required packages...
NumPy: 2.3.3
Pandas: 2.3.3
Matplotlib: 3.10.0
PyTorch: 2.9.0
All packages verified

=====================================
AVAILABLE SCENARIOS
=====================================

Available Scenarios:
================================================================================

** SCENARIO 1: MEC Unavailability **

[s1_base]
  Name: Scenario 1 - Base
  Description: MEC unavailable during timesteps 500-750 and 1250-1500
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s1_class1_90]
  Name: Scenario 1 - 90% Class 1
  Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s1_class2_90]
  Name: Scenario 1 - 90% Class 2
  Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s1_class3_90]
  Name: Scenario 1 - 90% Class 3
  Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s1_random]
  Name: Scenario 1 - Random Distribution
  Description: MEC unavailable 500-750, 1250-1500; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

--------------------------------------------------------------------------------

** SCENARIO 2: Communication Failure **

[s2_base]
  Name: Scenario 2 - Base
  Description: MEC stable, communication failure 500-1000
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s2_class1_90]
  Name: Scenario 2 - 90% Class 1
  Description: Communication failure 500-1000; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s2_class2_90]
  Name: Scenario 2 - 90% Class 2
  Description: Communication failure 500-1000; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s2_class3_90]
  Name: Scenario 2 - 90% Class 3
  Description: Communication failure 500-1000; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s2_random]
  Name: Scenario 2 - Random Distribution
  Description: Communication failure 500-1000; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

================================================================================

Predefined Scenario Sets:
================================================================================

s1:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random

s1_base:
  - s1_base

s2:
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

s2_base:
  - s2_base

all:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

================================================================================

=====================================
RUNNING ALL SCENARIOS: s1
=====================================
Start time: Wed Dec 17 21:02:15 EST 2025

[CMD] python -u run_all_scenarios.py --scenario-set s1 --episodes 200 --all --train --eval --plot


================================================================================
RUNNING ALL SCENARIOS
================================================================================
Scenarios to run: ['s1_class1_90', 's1_class2_90', 's1_class3_90', 's1_random']
Training episodes: 200
Train RL: True
Evaluate RL: True
Run baselines: True
Plot: True
Device: auto
================================================================================


################################################################################
# SCENARIO 1/4: s1_class1_90
################################################################################

Name: Scenario 1 - 90% Class 1
Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
Task distribution: Class1=90%, Class2=5%, Class3=5%


================================================================================
[s1_class1_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class1_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)

✅ Saved LOCAL results to results/scenarios/s1_class1_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.052811
Mean Latency: 0.030542 s
Mean Energy: 1.955 J
Final Battery: 0.00 J
Success Rate: 50.6%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class1_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 115.765983 s
Mean Energy: 0.003 J
Final Battery: 3793.44 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class1_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000001
Mean Latency: 0.004781 s
Mean Energy: 0.005 J
Final Battery: 3790.99 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s1_class1_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.009418
Mean Latency: 41.701466 s
Mean Energy: 1.372 J
Final Battery: 1055.91 J
Success Rate: 91.2%
Offload Ratio: 0.654
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_class1_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.028262
Mean Latency: 61.873454 s
Mean Energy: 1.923 J
Final Battery: 0.00 J
Success Rate: 75.8%
Offload Ratio: 0.038
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.052811            0.00 J          50.6%
mec                -0.025001         3793.44 J          75.0%
cloud              -0.000001         3790.99 J         100.0%
random             -0.009418         1055.91 J          91.2%
greedy_by_size     -0.028262            0.00 J          75.8%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class1_90/
================================================================================

[s1_class1_90] ✓ Baselines complete


================================================================================
[s1_class1_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.00 GB
  Memory reserved: 0.00 GB
  Max memory allocated: 0.00 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-733affd1-f6a6-5ed0-81c7-d56d63352f03
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 1
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
Task Distribution: Class1=90.0%, Class2=5.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 3508 | return=  -35.626 | avg_return(10)=  -35.626 | battery=   0.00 J
Episode   10/200 | steps= 6730 | return=   -7.977 | avg_return(10)=  -17.848 | battery=   0.00 J
Episode   20/200 | steps= 6745 | return=   -8.357 | avg_return(10)=  -10.360 | battery=   0.00 J
Episode   30/200 | steps= 7020 | return=  -11.481 | avg_return(10)=   -9.061 | battery=   0.00 J
Episode   40/200 | steps= 6585 | return=  -10.502 | avg_return(10)=   -9.832 | battery=   0.00 J
Episode   50/200 | steps= 6682 | return=   -8.169 | avg_return(10)=  -15.451 | battery=   0.00 J
Episode   60/200 | steps= 6791 | return=   -8.389 | avg_return(10)=  -93.967 | battery=   0.00 J
Episode   70/200 | steps= 7472 | return=   -7.861 | avg_return(10)=   -8.186 | battery=   0.00 J
Episode   80/200 | steps= 6947 | return=  -35.528 | avg_return(10)=  -12.651 | battery=   0.00 J
Episode   90/200 | steps= 7174 | return=   -7.437 | avg_return(10)=   -8.695 | battery=   0.00 J
Episode  100/200 | steps= 7447 | return=  -10.525 | avg_return(10)=   -8.754 | battery=   0.00 J
Episode  110/200 | steps= 6905 | return=   -9.075 | avg_return(10)=  -14.283 | battery=   0.00 J
Episode  120/200 | steps= 7221 | return=   -8.920 | avg_return(10)=   -9.674 | battery=   0.00 J
Episode  130/200 | steps= 6843 | return=   -9.518 | avg_return(10)=  -40.528 | battery=   0.00 J
Episode  140/200 | steps= 7494 | return=   -8.214 | avg_return(10)=   -9.647 | battery=   0.00 J
Episode  150/200 | steps= 7728 | return=  -10.195 | avg_return(10)=  -13.550 | battery=   0.00 J
Episode  160/200 | steps= 6833 | return=  -12.698 | avg_return(10)=  -23.754 | battery=   0.00 J
Episode  170/200 | steps= 7681 | return=   -8.041 | avg_return(10)=  -64.999 | battery=   0.00 J
Episode  180/200 | steps= 7609 | return=   -8.667 | avg_return(10)=  -10.398 | battery=   0.00 J
Episode  190/200 | steps= 7414 | return=  -54.353 | avg_return(10)=  -16.119 | battery=   0.00 J
Episode  200/200 | steps= 6770 | return=  -99.609 | avg_return(10)=  -17.303 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 1
Total episodes: 200
Final episode return: -99.609
Avg return (last 10): -17.303
Best episode return: -5.947
================================================================================

✅ Saved actor to results/scenarios/s1_class1_90/actor.pt
✅ Saved critic to results/scenarios/s1_class1_90/critic.pt

[s1_class1_90] ✓ RL training complete


================================================================================
[s1_class1_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 1
================================================================================
Loading model from: results/scenarios/s1_class1_90

✅ Loaded trained actor from results/scenarios/s1_class1_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class1_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000412
Mean Latency: 0.021566 s
Mean Energy: 1.121 J
Final Battery: 1738.65 J
Success Rate: 100.0%
Offload Ratio: 0.643
================================================================================

[s1_class1_90] ✓ RL evaluation complete
  Mean QoE: -0.000412
  Final Battery: 1738.65 J
  Success Rate: 100.0%

[s1_class1_90] Time elapsed: 96.5 minutes


################################################################################
# SCENARIO 2/4: s1_class2_90
################################################################################

Name: Scenario 1 - 90% Class 2
Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
Task distribution: Class1=5%, Class2=90%, Class3=5%


================================================================================
[s1_class2_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class2_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved LOCAL results to results/scenarios/s1_class2_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.062138
Mean Latency: 0.030606 s
Mean Energy: 1.959 J
Final Battery: 0.00 J
Success Rate: 42.6%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class2_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 154.679213 s
Mean Energy: 0.004 J
Final Battery: 3792.40 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class2_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000001
Mean Latency: 0.005568 s
Mean Energy: 0.005 J
Final Battery: 3789.51 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s1_class2_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.009124
Mean Latency: 38.860337 s
Mean Energy: 1.557 J
Final Battery: 686.98 J
Success Rate: 91.7%
Offload Ratio: 0.667
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_class2_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.046936
Mean Latency: 30.087888 s
Mean Energy: 1.943 J
Final Battery: 0.00 J
Success Rate: 56.8%
Offload Ratio: 0.025
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.062138            0.00 J          42.6%
mec                -0.025001         3792.40 J          75.0%
cloud              -0.000001         3789.51 J         100.0%
random             -0.009124          686.98 J          91.7%
greedy_by_size     -0.046936            0.00 J          56.8%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class2_90/
================================================================================

[s1_class2_90] ✓ Baselines complete


================================================================================
[s1_class2_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-733affd1-f6a6-5ed0-81c7-d56d63352f03
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 2
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
Task Distribution: Class1=5.0%, Class2=90.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 2885 | return=   -7.671 | avg_return(10)=   -7.671 | battery=   0.00 J
Episode   10/200 | steps= 6464 | return=   -9.860 | avg_return(10)=  -12.557 | battery=   0.00 J
Episode   20/200 | steps= 7406 | return= -108.005 | avg_return(10)=  -40.759 | battery=   0.00 J
Episode   30/200 | steps= 7848 | return=   -7.476 | avg_return(10)=  -10.281 | battery=   0.00 J
Episode   40/200 | steps= 7831 | return=   -8.491 | avg_return(10)=  -10.039 | battery=   0.00 J
Episode   50/200 | steps= 7664 | return=   -7.581 | avg_return(10)=  -22.165 | battery=   0.00 J
Episode   60/200 | steps= 7442 | return=   -7.417 | avg_return(10)=  -12.474 | battery=   0.00 J
Episode   70/200 | steps= 5534 | return=   -7.625 | avg_return(10)=  -10.152 | battery=   0.00 J
Episode   80/200 | steps= 8151 | return=   -9.476 | avg_return(10)=   -9.368 | battery=   0.00 J
Episode   90/200 | steps= 9386 | return=  -10.199 | avg_return(10)=   -8.316 | battery=   0.00 J
Episode  100/200 | steps= 8207 | return=  -15.474 | avg_return(10)=  -10.317 | battery=   0.00 J
Episode  110/200 | steps= 6844 | return=   -6.643 | avg_return(10)=  -13.270 | battery=   0.00 J
Episode  120/200 | steps= 7581 | return=   -8.062 | avg_return(10)=  -13.853 | battery=   0.00 J
Episode  130/200 | steps= 7821 | return=   -8.836 | avg_return(10)=  -10.723 | battery=   0.00 J
Episode  140/200 | steps= 7302 | return=   -8.579 | avg_return(10)=   -9.635 | battery=   0.00 J
Episode  150/200 | steps= 8310 | return=   -7.396 | avg_return(10)=   -8.545 | battery=   0.00 J
Episode  160/200 | steps= 8817 | return=   -8.171 | avg_return(10)=   -7.965 | battery=   0.00 J
Episode  170/200 | steps= 6315 | return=   -6.891 | avg_return(10)=   -9.717 | battery=   0.00 J
Episode  180/200 | steps= 8119 | return=  -13.729 | avg_return(10)=   -8.815 | battery=   0.00 J
Episode  190/200 | steps= 8189 | return=  -10.608 | avg_return(10)=   -8.852 | battery=   0.00 J
Episode  200/200 | steps= 8074 | return=   -8.240 | avg_return(10)=  -11.132 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 2
Total episodes: 200
Final episode return: -8.240
Avg return (last 10): -11.132
Best episode return: -6.637
================================================================================

✅ Saved actor to results/scenarios/s1_class2_90/actor.pt
✅ Saved critic to results/scenarios/s1_class2_90/critic.pt

[s1_class2_90] ✓ RL training complete


================================================================================
[s1_class2_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 2
================================================================================
Loading model from: results/scenarios/s1_class2_90

✅ Loaded trained actor from results/scenarios/s1_class2_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class2_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000245
Mean Latency: 0.017522 s
Mean Energy: 0.773 J
Final Battery: 2433.40 J
Success Rate: 100.0%
Offload Ratio: 0.798
================================================================================

[s1_class2_90] ✓ RL evaluation complete
  Mean QoE: -0.000245
  Final Battery: 2433.40 J
  Success Rate: 100.0%

[s1_class2_90] Time elapsed: 103.8 minutes


################################################################################
# SCENARIO 3/4: s1_class3_90
################################################################################

Name: Scenario 1 - 90% Class 3
Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
Task distribution: Class1=5%, Class2=5%, Class3=90%


================================================================================
[s1_class3_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class3_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class3_90...

✅ Saved LOCAL results to results/scenarios/s1_class3_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.096324
Mean Latency: 0.031316 s
Mean Energy: 2.004 J
Final Battery: 0.00 J
Success Rate: 7.1%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class3_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025006
Mean Latency: 1341.445565 s
Mean Energy: 0.023 J
Final Battery: 3754.67 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class3_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000008
Mean Latency: 0.032535 s
Mean Energy: 0.031 J
Final Battery: 3738.71 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)

✅ Saved RANDOM results to results/scenarios/s1_class3_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.081021
Mean Latency: 0.037138 s
Mean Energy: 1.981 J
Final Battery: 0.00 J
Success Rate: 22.1%
Offload Ratio: 0.148
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_class3_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.022731
Mean Latency: 1338.006669 s
Mean Energy: 0.290 J
Final Battery: 3219.47 J
Success Rate: 77.3%
Offload Ratio: 0.911
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.096324            0.00 J           7.1%
mec                -0.025006         3754.67 J          75.0%
cloud              -0.000008         3738.71 J         100.0%
random             -0.081021            0.00 J          22.1%
greedy_by_size     -0.022731         3219.47 J          77.3%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class3_90/
================================================================================

[s1_class3_90] ✓ Baselines complete


================================================================================
[s1_class3_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-733affd1-f6a6-5ed0-81c7-d56d63352f03
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 3
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
Task Distribution: Class1=5.0%, Class2=5.0%, Class3=90.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps=  726 | return=   -7.619 | avg_return(10)=   -7.619 | battery=   0.00 J
Episode   10/200 | steps= 6322 | return=  -12.389 | avg_return(10)=  -10.102 | battery=   0.00 J
Episode   20/200 | steps=18139 | return= -110.740 | avg_return(10)=  -22.372 | battery=   0.00 J
Episode   30/200 | steps=13564 | return=  -12.374 | avg_return(10)=  -12.430 | battery=   0.00 J
Episode   40/200 | steps=12965 | return=  -11.282 | avg_return(10)=   -9.685 | battery=   0.00 J
Episode   50/200 | steps= 9304 | return=  -10.479 | avg_return(10)=  -12.396 | battery=   0.00 J
Episode   60/200 | steps= 9800 | return=   -9.122 | avg_return(10)=  -10.207 | battery=   0.00 J
Episode   70/200 | steps=11108 | return=  -12.196 | avg_return(10)=  -15.333 | battery=   0.00 J
Episode   80/200 | steps=11129 | return=  -11.911 | avg_return(10)=  -10.690 | battery=   0.00 J
Episode   90/200 | steps= 9445 | return=  -20.913 | avg_return(10)=  -10.357 | battery=   0.00 J
Episode  100/200 | steps= 8066 | return=   -6.787 | avg_return(10)=  -10.637 | battery=   0.00 J
Episode  110/200 | steps= 7989 | return=   -7.241 | avg_return(10)=   -9.403 | battery=   0.00 J
Episode  120/200 | steps= 8500 | return=  -13.034 | avg_return(10)=  -10.724 | battery=   0.00 J
Episode  130/200 | steps=10479 | return=  -14.479 | avg_return(10)=  -16.221 | battery=   0.00 J
Episode  140/200 | steps= 7977 | return=   -6.511 | avg_return(10)=  -10.981 | battery=   0.00 J
Episode  150/200 | steps= 9900 | return=  -13.032 | avg_return(10)=  -10.627 | battery=   0.00 J
Episode  160/200 | steps= 9768 | return=  -11.924 | avg_return(10)=  -12.021 | battery=   0.00 J
Episode  170/200 | steps= 9030 | return=  -14.881 | avg_return(10)=  -12.357 | battery=   0.00 J
Episode  180/200 | steps= 8911 | return=   -7.574 | avg_return(10)=   -9.761 | battery=   0.00 J
Episode  190/200 | steps= 8967 | return=  -10.602 | avg_return(10)=  -11.363 | battery=   0.00 J
Episode  200/200 | steps= 8308 | return=   -6.222 | avg_return(10)=  -13.371 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 3
Total episodes: 200
Final episode return: -6.222
Avg return (last 10): -13.371
Best episode return: -4.770
================================================================================

✅ Saved actor to results/scenarios/s1_class3_90/actor.pt
✅ Saved critic to results/scenarios/s1_class3_90/critic.pt

[s1_class3_90] ✓ RL training complete


================================================================================
[s1_class3_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 3
================================================================================
Loading model from: results/scenarios/s1_class3_90

✅ Loaded trained actor from results/scenarios/s1_class3_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class3_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000546
Mean Latency: 0.058871 s
Mean Energy: 1.331 J
Final Battery: 1318.11 J
Success Rate: 100.0%
Offload Ratio: 0.933
================================================================================

[s1_class3_90] ✓ RL evaluation complete
  Mean QoE: -0.000546
  Final Battery: 1318.11 J
  Success Rate: 100.0%

[s1_class3_90] Time elapsed: 135.7 minutes


################################################################################
# SCENARIO 4/4: s1_random
################################################################################

Name: Scenario 1 - Random Distribution
Description: MEC unavailable 500-750, 1250-1500; equal task distribution
Task distribution: Class1=33%, Class2=34%, Class3=33%


================================================================================
[s1_random] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_random
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_random...
  Progress: 200/2000 (10.0%)

✅ Saved LOCAL results to results/scenarios/s1_random/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.086748
Mean Latency: 0.031128 s
Mean Energy: 1.992 J
Final Battery: 0.00 J
Success Rate: 16.8%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_random/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025003
Mean Latency: 523.521162 s
Mean Energy: 0.010 J
Final Battery: 3779.30 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_random/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000003
Mean Latency: 0.014353 s
Mean Energy: 0.014 J
Final Battery: 3772.97 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)

✅ Saved RANDOM results to results/scenarios/s1_random/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.058249
Mean Latency: 73.637485 s
Mean Energy: 1.962 J
Final Battery: 0.00 J
Success Rate: 49.1%
Offload Ratio: 0.354
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_random/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.023344
Mean Latency: 457.757224 s
Mean Energy: 1.912 J
Final Battery: 0.00 J
Success Rate: 80.5%
Offload Ratio: 0.269
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.086748            0.00 J          16.8%
mec                -0.025003         3779.30 J          75.0%
cloud              -0.000003         3772.97 J         100.0%
random             -0.058249            0.00 J          49.1%
greedy_by_size     -0.023344            0.00 J          80.5%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_random/
================================================================================

[s1_random] ✓ Baselines complete


================================================================================
[s1_random] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-733affd1-f6a6-5ed0-81c7-d56d63352f03
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - Random Distribution
================================================================================
Description: MEC unavailable 500-750, 1250-1500; equal task distribution
Task Distribution: Class1=33.0%, Class2=34.0%, Class3=33.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 1436 | return=   -7.323 | avg_return(10)=   -7.323 | battery=   0.00 J
Episode   10/200 | steps= 5417 | return=  -10.466 | avg_return(10)=  -17.981 | battery=   0.00 J
Episode   20/200 | steps= 6973 | return=   -9.648 | avg_return(10)=   -9.531 | battery=   0.00 J
Episode   30/200 | steps= 7097 | return=   -8.362 | avg_return(10)=   -9.927 | battery=   0.00 J
Episode   40/200 | steps= 6859 | return=   -8.068 | avg_return(10)=   -8.892 | battery=   0.00 J
Episode   50/200 | steps= 7322 | return=   -8.624 | avg_return(10)=   -8.716 | battery=   0.00 J
Episode   60/200 | steps= 7031 | return=   -8.829 | avg_return(10)=  -11.121 | battery=   0.00 J
Episode   70/200 | steps= 7001 | return=   -7.346 | avg_return(10)=  -10.010 | battery=   0.00 J
Episode   80/200 | steps= 6720 | return=   -8.870 | avg_return(10)=  -10.850 | battery=   0.00 J
Episode   90/200 | steps= 8097 | return=   -6.989 | avg_return(10)=  -21.294 | battery=   0.00 J
Episode  100/200 | steps= 7786 | return=   -8.175 | avg_return(10)=   -9.957 | battery=   0.00 J
Episode  110/200 | steps= 7509 | return= -137.825 | avg_return(10)=  -22.558 | battery=   0.00 J
Episode  120/200 | steps= 7137 | return=   -8.820 | avg_return(10)=   -9.611 | battery=   0.00 J
Episode  130/200 | steps= 6560 | return=   -8.821 | avg_return(10)=   -9.157 | battery=   0.00 J
Episode  140/200 | steps= 6970 | return=   -7.683 | avg_return(10)=  -15.597 | battery=   0.00 J
Episode  150/200 | steps= 7209 | return=   -9.831 | avg_return(10)=  -10.054 | battery=   0.00 J
Episode  160/200 | steps= 7663 | return=  -17.366 | avg_return(10)=  -11.938 | battery=   0.00 J
Episode  170/200 | steps= 8935 | return=  -19.511 | avg_return(10)=  -10.909 | battery=   0.00 J
Episode  180/200 | steps= 7537 | return=   -7.512 | avg_return(10)=   -8.463 | battery=   0.00 J
Episode  190/200 | steps= 7977 | return=   -8.860 | avg_return(10)=  -10.773 | battery=   0.00 J
Episode  200/200 | steps= 8257 | return=  -16.937 | avg_return(10)=   -9.450 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - Random Distribution
Total episodes: 200
Final episode return: -16.937
Avg return (last 10): -9.450
Best episode return: -5.724
================================================================================

✅ Saved actor to results/scenarios/s1_random/actor.pt
✅ Saved critic to results/scenarios/s1_random/critic.pt

[s1_random] ✓ RL training complete


================================================================================
[s1_random] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - Random Distribution
================================================================================
Loading model from: results/scenarios/s1_random

✅ Loaded trained actor from results/scenarios/s1_random/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_random/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000275
Mean Latency: 0.030678 s
Mean Energy: 0.846 J
Final Battery: 2287.76 J
Success Rate: 100.0%
Offload Ratio: 0.844
================================================================================

[s1_random] ✓ RL evaluation complete
  Mean QoE: -0.000275
  Final Battery: 2287.76 J
  Success Rate: 100.0%

[s1_random] Time elapsed: 103.5 minutes


================================================================================
GENERATING PLOTS
================================================================================

Generating Scenario 1 complete figure...

Plotting Class 1 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

Plotting Class 2 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

Plotting Class 3 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

Plotting Random (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

✅ Figure saved to: results/scenarios/scenario_1_complete_figure.png
✓ Scenario 1 plots generated


================================================================================
ALL SCENARIOS COMPLETE
================================================================================
Total time: 439.5 minutes

RL Agent Results Summary:
--------------------------------------------------------------------------------
Scenario                 Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
s1_class1_90            -0.000412         1738.65 J         100.0%
s1_class2_90            -0.000245         2433.40 J         100.0%
s1_class3_90            -0.000546         1318.11 J         100.0%
s1_random               -0.000275         2287.76 J         100.0%
--------------------------------------------------------------------------------

Results saved to: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/results/scenarios/
================================================================================


End time: Thu Dec 18 04:21:51 EST 2025

=====================================
 Job Finished
=====================================

====================================
 RL All Scenarios Job Started
 Job ID: 6025890
 Node: g30
 Time: Thu Dec 18 22:13:04 EST 2025
====================================

[CONFIG] Scenario Set: s2
[CONFIG] Episodes per scenario: 200
[CONFIG] Train: true
[CONFIG] Evaluate: true
[CONFIG] Plot: true

[SETUP] Loading modules...
[SETUP] Loaded modules:

Currently Loaded Modules:
  1) CCconfig            6) ucx/1.14.1            11) flexiblas/3.3.1
  2) gentoo/2023   (S)   7) libfabric/1.18.0      12) imkl/2023.2.0   (math)
  3) gcccore/.12.3 (H)   8) pmix/4.2.4            13) StdEnv/2023     (S)
  4) gcc/12.3      (t)   9) ucc/1.2.0             14) python/3.13.2   (t)
  5) hwloc/2.9.1        10) openmpi/4.1.5    (m)

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 


[SETUP] Working directory: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL

[SETUP] Activating virtual environment...
[SETUP] ✓ Virtual environment activated

=====================================
PYTHON & PYTORCH DIAGNOSTICS
=====================================
Python version: Python 3.13.2
Python path: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/bin/python
Pip version: pip 24.3.1 from /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/lib/python3.13/site-packages/pip (python 3.13)

[PYTORCH] Testing PyTorch installation...
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
GPU count: 1
GPU name: NVIDIA H100 80GB HBM3 MIG 1g.10gb

=====================================
ENVIRONMENT VARIABLES
=====================================
SLURM_JOB_ID: 6025890
SLURM_JOB_NAME: rl_all_s2
SLURM_NODELIST: g30
SLURM_CPUS_PER_TASK: 4
SLURM_MEM_PER_NODE: 32768
CUDA_VISIBLE_DEVICES: MIG-ba7859c1-a377-57cf-a799-b2d94d5b5277

[SETUP] Setting CPU threading limits...
[SETUP] OMP_NUM_THREADS=4
[SETUP] MKL_NUM_THREADS=4

=====================================
GPU DIAGNOSTICS (nvidia-smi)
=====================================
Thu Dec 18 22:13:09 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                   On |
| N/A   37C    P0            187W /  700W |   17204MiB /  81559MiB |     N/A      Default |
|                                         |                        |              Enabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| MIG devices:                                                                            |
+------------------+----------------------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |              Shared Memory-Usage |        Vol|        Shared         |
|      ID  ID  Dev |                Shared BAR1-Usage | SM     Unc| CE ENC  DEC  OFA  JPG |
|                  |                                  |        ECC|                       |
|==================+==================================+===========+=======================|
|  0   10   0   0  |              15MiB /  9984MiB    | 16      0 |  1   0    1    0    1 |
|                  |               0MiB /  6185MiB    |           |                       |
+------------------+----------------------------------+-----------+-----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

[GPU] ✓ GPU detected

=====================================
PYTHON PACKAGE VERIFICATION
=====================================
[PACKAGES] Checking required packages...
NumPy: 2.3.3
Pandas: 2.3.3
Matplotlib: 3.10.0
PyTorch: 2.9.0
All packages verified

=====================================
AVAILABLE SCENARIOS
=====================================

Available Scenarios:
================================================================================

** SCENARIO 1: MEC Unavailability **

[s1_base]
  Name: Scenario 1 - Base
  Description: MEC unavailable during timesteps 500-750 and 1250-1500
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s1_class1_90]
  Name: Scenario 1 - 90% Class 1
  Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s1_class2_90]
  Name: Scenario 1 - 90% Class 2
  Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s1_class3_90]
  Name: Scenario 1 - 90% Class 3
  Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s1_random]
  Name: Scenario 1 - Random Distribution
  Description: MEC unavailable 500-750, 1250-1500; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

--------------------------------------------------------------------------------

** SCENARIO 2: Communication Failure **

[s2_base]
  Name: Scenario 2 - Base
  Description: MEC stable, communication failure 500-1000
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s2_class1_90]
  Name: Scenario 2 - 90% Class 1
  Description: Communication failure 500-1000; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s2_class2_90]
  Name: Scenario 2 - 90% Class 2
  Description: Communication failure 500-1000; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s2_class3_90]
  Name: Scenario 2 - 90% Class 3
  Description: Communication failure 500-1000; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s2_random]
  Name: Scenario 2 - Random Distribution
  Description: Communication failure 500-1000; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

================================================================================

Predefined Scenario Sets:
================================================================================

s1:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random

s1_base:
  - s1_base

s2:
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

s2_base:
  - s2_base

all:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

================================================================================

=====================================
RUNNING ALL SCENARIOS: s2
=====================================
Start time: Thu Dec 18 22:13:15 EST 2025

[CMD] python -u run_all_scenarios.py --scenario-set s2 --episodes 200 --all --train --eval --plot


================================================================================
RUNNING ALL SCENARIOS
================================================================================
Scenarios to run: ['s2_class1_90', 's2_class2_90', 's2_class3_90', 's2_random']
Training episodes: 200
Train RL: True
Evaluate RL: True
Run baselines: True
Plot: True
Device: auto
================================================================================


################################################################################
# SCENARIO 1/4: s2_class1_90
################################################################################

Name: Scenario 2 - 90% Class 1
Description: Communication failure 500-1000; 90% delay-sensitive tasks
Task distribution: Class1=90%, Class2=5%, Class3=5%


================================================================================
[s2_class1_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s2_class1_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s2_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved LOCAL results to results/scenarios/s2_class1_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.098973
Mean Latency: 0.030518 s
Mean Energy: 1.953 J
Final Battery: 0.00 J
Success Rate: 2.4%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s2_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s2_class1_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 0.118892 s
Mean Energy: 0.003 J
Final Battery: 3793.43 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s2_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s2_class1_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.062401
Mean Latency: 0.107482 s
Mean Energy: 0.003 J
Final Battery: 3793.59 J
Success Rate: 37.6%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s2_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s2_class1_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.060690
Mean Latency: 0.095208 s
Mean Energy: 1.299 J
Final Battery: 1202.10 J
Success Rate: 39.5%
Offload Ratio: 0.667
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s2_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s2_class1_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.097202
Mean Latency: 0.105747 s
Mean Energy: 1.925 J
Final Battery: 0.00 J
Success Rate: 2.8%
Offload Ratio: 0.040
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.098973            0.00 J           2.4%
mec                -0.025001         3793.43 J          75.0%
cloud              -0.062401         3793.59 J          37.6%
random             -0.060690         1202.10 J          39.5%
greedy_by_size     -0.097202            0.00 J           2.8%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s2_class1_90/
================================================================================

[s2_class1_90] ✓ Baselines complete


================================================================================
[s2_class1_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.00 GB
  Memory reserved: 0.00 GB
  Max memory allocated: 0.00 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-ba7859c1-a377-57cf-a799-b2d94d5b5277
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 2 - 90% Class 1
================================================================================
Description: Communication failure 500-1000; 90% delay-sensitive tasks
Task Distribution: Class1=90.0%, Class2=5.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 7881 | return= -321.708 | avg_return(10)= -321.708 | battery=   0.00 J
Episode   10/200 | steps= 6440 | return= -145.554 | avg_return(10)= -181.933 | battery=   0.00 J
Episode   20/200 | steps= 6353 | return= -132.198 | avg_return(10)= -142.022 | battery=   0.00 J
Episode   30/200 | steps= 6272 | return= -136.636 | avg_return(10)= -129.326 | battery=   0.00 J
Episode   40/200 | steps= 6193 | return= -122.130 | avg_return(10)= -123.637 | battery=   0.00 J
Episode   50/200 | steps= 6312 | return= -193.905 | avg_return(10)= -143.405 | battery=   0.00 J
Episode   60/200 | steps= 6361 | return= -126.097 | avg_return(10)= -125.171 | battery=   0.00 J
Episode   70/200 | steps= 6291 | return= -121.091 | avg_return(10)= -124.054 | battery=   0.00 J
Episode   80/200 | steps= 6100 | return= -120.082 | avg_return(10)= -127.931 | battery=   0.00 J
Episode   90/200 | steps= 6383 | return= -139.957 | avg_return(10)= -129.569 | battery=   0.00 J
Episode  100/200 | steps= 6373 | return= -147.600 | avg_return(10)= -130.241 | battery=   0.00 J
Episode  110/200 | steps= 6235 | return= -125.249 | avg_return(10)= -126.017 | battery=   0.00 J
Episode  120/200 | steps= 6286 | return= -124.892 | avg_return(10)= -126.957 | battery=   0.00 J
Episode  130/200 | steps= 6072 | return= -116.598 | avg_return(10)= -121.165 | battery=   0.00 J
Episode  140/200 | steps= 6156 | return= -120.109 | avg_return(10)= -124.293 | battery=   0.00 J
Episode  150/200 | steps= 5973 | return=  -86.820 | avg_return(10)= -120.279 | battery=   0.00 J
Episode  160/200 | steps= 6088 | return= -122.447 | avg_return(10)= -152.924 | battery=   0.00 J
Episode  170/200 | steps= 6126 | return= -128.687 | avg_return(10)= -121.568 | battery=   0.00 J
Episode  180/200 | steps= 6644 | return= -159.308 | avg_return(10)= -129.846 | battery=   0.00 J
Episode  190/200 | steps= 6451 | return= -155.523 | avg_return(10)= -133.272 | battery=   0.00 J
Episode  200/200 | steps= 6158 | return= -117.996 | avg_return(10)= -125.261 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 2 - 90% Class 1
Total episodes: 200
Final episode return: -117.996
Avg return (last 10): -125.261
Best episode return: -86.820
================================================================================

✅ Saved actor to results/scenarios/s2_class1_90/actor.pt
✅ Saved critic to results/scenarios/s2_class1_90/critic.pt

[s2_class1_90] ✓ RL training complete


================================================================================
[s2_class1_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 2 - 90% Class 1
================================================================================
Loading model from: results/scenarios/s2_class1_90

✅ Loaded trained actor from results/scenarios/s2_class1_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s2_class1_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000414
Mean Latency: 0.010075 s
Mean Energy: 0.242 J
Final Battery: 3495.34 J
Success Rate: 99.7%
Offload Ratio: 0.991
================================================================================

[s2_class1_90] ✓ RL evaluation complete
  Mean QoE: -0.000414
  Final Battery: 3495.34 J
  Success Rate: 99.7%

[s2_class1_90] Time elapsed: 88.4 minutes


################################################################################
# SCENARIO 2/4: s2_class2_90
################################################################################

Name: Scenario 2 - 90% Class 2
Description: Communication failure 500-1000; 90% energy-sensitive tasks
Task distribution: Class1=5%, Class2=90%, Class3=5%


================================================================================
[s2_class2_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s2_class2_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s2_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)

✅ Saved LOCAL results to results/scenarios/s2_class2_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.098790
Mean Latency: 0.030666 s
Mean Energy: 1.963 J
Final Battery: 0.00 J
Success Rate: 2.2%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s2_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s2_class2_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 0.165259 s
Mean Energy: 0.004 J
Final Battery: 3792.36 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s2_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s2_class2_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.027151
Mean Latency: 0.142943 s
Mean Energy: 0.004 J
Final Battery: 3792.07 J
Success Rate: 72.9%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s2_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s2_class2_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.048368
Mean Latency: 0.132448 s
Mean Energy: 1.533 J
Final Battery: 734.50 J
Success Rate: 51.8%
Offload Ratio: 0.682
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s2_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s2_class2_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.098101
Mean Latency: 0.093316 s
Mean Energy: 1.943 J
Final Battery: 0.00 J
Success Rate: 1.9%
Offload Ratio: 0.030
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.098790            0.00 J           2.2%
mec                -0.025001         3792.36 J          75.0%
cloud              -0.027151         3792.07 J          72.9%
random             -0.048368          734.50 J          51.8%
greedy_by_size     -0.098101            0.00 J           1.9%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s2_class2_90/
================================================================================

[s2_class2_90] ✓ Baselines complete


================================================================================
[s2_class2_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-ba7859c1-a377-57cf-a799-b2d94d5b5277
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 2 - 90% Class 2
================================================================================
Description: Communication failure 500-1000; 90% energy-sensitive tasks
Task Distribution: Class1=5.0%, Class2=90.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 9189 | return= -434.188 | avg_return(10)= -434.188 | battery=   0.00 J
Episode   10/200 | steps= 6387 | return= -134.102 | avg_return(10)= -195.743 | battery=   0.00 J
Episode   20/200 | steps= 6297 | return= -137.176 | avg_return(10)= -141.423 | battery=   0.00 J
Episode   30/200 | steps= 6082 | return= -112.703 | avg_return(10)= -122.976 | battery=   0.00 J
Episode   40/200 | steps= 6446 | return= -137.739 | avg_return(10)= -123.039 | battery=   0.00 J
Episode   50/200 | steps= 6352 | return= -134.543 | avg_return(10)= -116.022 | battery=   0.00 J
Episode   60/200 | steps= 6030 | return= -110.814 | avg_return(10)= -157.826 | battery=   0.00 J
Episode   70/200 | steps= 6507 | return= -139.718 | avg_return(10)= -113.200 | battery=   0.00 J
Episode   80/200 | steps= 6393 | return= -136.110 | avg_return(10)= -131.920 | battery=   0.00 J
Episode   90/200 | steps= 6196 | return= -122.298 | avg_return(10)= -114.270 | battery=   0.00 J
Episode  100/200 | steps= 6210 | return= -124.187 | avg_return(10)= -117.863 | battery=   0.00 J
Episode  110/200 | steps= 6150 | return= -115.484 | avg_return(10)= -119.559 | battery=   0.00 J
Episode  120/200 | steps= 6083 | return= -109.365 | avg_return(10)= -104.808 | battery=   0.00 J
Episode  130/200 | steps= 6125 | return= -110.302 | avg_return(10)= -106.686 | battery=   0.00 J
Episode  140/200 | steps= 6226 | return= -119.074 | avg_return(10)= -117.909 | battery=   0.00 J
Episode  150/200 | steps= 6052 | return= -104.873 | avg_return(10)= -121.222 | battery=   0.00 J
Episode  160/200 | steps= 6350 | return= -130.829 | avg_return(10)= -123.535 | battery=   0.00 J
Episode  170/200 | steps= 6061 | return= -115.092 | avg_return(10)= -115.513 | battery=   0.00 J
Episode  180/200 | steps= 5956 | return= -102.644 | avg_return(10)= -106.967 | battery=   0.00 J
Episode  190/200 | steps= 6319 | return= -126.174 | avg_return(10)= -116.599 | battery=   0.00 J
Episode  200/200 | steps= 6061 | return= -113.479 | avg_return(10)= -111.898 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 2 - 90% Class 2
Total episodes: 200
Final episode return: -113.479
Avg return (last 10): -111.898
Best episode return: -72.727
================================================================================

✅ Saved actor to results/scenarios/s2_class2_90/actor.pt
✅ Saved critic to results/scenarios/s2_class2_90/critic.pt

[s2_class2_90] ✓ RL training complete


================================================================================
[s2_class2_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 2 - 90% Class 2
================================================================================
Loading model from: results/scenarios/s2_class2_90

✅ Loaded trained actor from results/scenarios/s2_class2_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s2_class2_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000416
Mean Latency: 0.015667 s
Mean Energy: 0.250 J
Final Battery: 3480.22 J
Success Rate: 99.7%
Offload Ratio: 0.991
================================================================================

[s2_class2_90] ✓ RL evaluation complete
  Mean QoE: -0.000416
  Final Battery: 3480.22 J
  Success Rate: 99.7%

[s2_class2_90] Time elapsed: 86.4 minutes


################################################################################
# SCENARIO 3/4: s2_class3_90
################################################################################

Name: Scenario 2 - 90% Class 3
Description: Communication failure 500-1000; 90% insensitive tasks
Task distribution: Class1=5%, Class2=5%, Class3=90%


================================================================================
[s2_class3_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s2_class3_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s2_class3_90...

✅ Saved LOCAL results to results/scenarios/s2_class3_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.096260
Mean Latency: 0.031160 s
Mean Energy: 1.994 J
Final Battery: 0.00 J
Success Rate: 6.4%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s2_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s2_class3_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025006
Mean Latency: 1.413403 s
Mean Energy: 0.022 J
Final Battery: 3755.22 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s2_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s2_class3_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.026906
Mean Latency: 1.349407 s
Mean Energy: 0.023 J
Final Battery: 3754.44 J
Success Rate: 73.1%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s2_class3_90...
  Progress: 200/2000 (10.0%)

✅ Saved RANDOM results to results/scenarios/s2_class3_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.085288
Mean Latency: 0.036797 s
Mean Energy: 1.994 J
Final Battery: 0.00 J
Success Rate: 18.8%
Offload Ratio: 0.127
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s2_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s2_class3_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.031806
Mean Latency: 1.375906 s
Mean Energy: 0.314 J
Final Battery: 3172.12 J
Success Rate: 68.2%
Offload Ratio: 0.906
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.096260            0.00 J           6.4%
mec                -0.025006         3755.22 J          75.0%
cloud              -0.026906         3754.44 J          73.1%
random             -0.085288            0.00 J          18.8%
greedy_by_size     -0.031806         3172.12 J          68.2%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s2_class3_90/
================================================================================

[s2_class3_90] ✓ Baselines complete


================================================================================
[s2_class3_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-ba7859c1-a377-57cf-a799-b2d94d5b5277
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 2 - 90% Class 3
================================================================================
Description: Communication failure 500-1000; 90% insensitive tasks
Task Distribution: Class1=5.0%, Class2=5.0%, Class3=90.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps=  787 | return=   -9.595 | avg_return(10)=   -9.595 | battery=   0.00 J
Episode   10/200 | steps= 4956 | return=  -13.574 | avg_return(10)=  -64.479 | battery=   0.00 J
Episode   20/200 | steps= 5000 | return=  -10.338 | avg_return(10)=  -14.062 | battery=   0.00 J
Episode   30/200 | steps= 5026 | return=  -10.018 | avg_return(10)=   -9.990 | battery=   0.00 J
Episode   40/200 | steps= 5120 | return=   -9.608 | avg_return(10)=  -14.460 | battery=   0.00 J
Episode   50/200 | steps= 6845 | return= -198.023 | avg_return(10)=  -80.760 | battery=   0.00 J
Episode   60/200 | steps= 7565 | return= -263.635 | avg_return(10)= -287.777 | battery=   0.00 J
Episode   70/200 | steps= 8918 | return= -399.333 | avg_return(10)= -328.613 | battery=   0.00 J
Episode   80/200 | steps= 8840 | return= -395.679 | avg_return(10)= -236.853 | battery=   0.00 J
Episode   90/200 | steps= 8659 | return= -388.774 | avg_return(10)= -288.326 | battery=   0.00 J
Episode  100/200 | steps= 8004 | return= -314.375 | avg_return(10)= -271.562 | battery=   0.00 J
Episode  110/200 | steps= 5800 | return=  -82.433 | avg_return(10)= -163.598 | battery=   0.00 J
Episode  120/200 | steps= 5549 | return=  -59.140 | avg_return(10)= -150.522 | battery=   0.00 J
Episode  130/200 | steps= 6070 | return= -117.872 | avg_return(10)= -142.627 | battery=   0.00 J
Episode  140/200 | steps= 5967 | return= -112.329 | avg_return(10)= -139.763 | battery=   0.00 J
Episode  150/200 | steps= 5755 | return=  -80.559 | avg_return(10)= -120.334 | battery=   0.00 J
Episode  160/200 | steps= 6315 | return= -232.127 | avg_return(10)= -184.026 | battery=   0.00 J
Episode  170/200 | steps= 6708 | return= -203.225 | avg_return(10)= -181.710 | battery=   0.00 J
Episode  180/200 | steps= 5572 | return=  -50.387 | avg_return(10)= -193.319 | battery=   0.00 J
Episode  190/200 | steps= 5337 | return=  -43.694 | avg_return(10)= -213.246 | battery=   0.00 J
Episode  200/200 | steps= 7297 | return= -252.412 | avg_return(10)= -107.593 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 2 - 90% Class 3
Total episodes: 200
Final episode return: -252.412
Avg return (last 10): -107.593
Best episode return: -6.598
================================================================================

✅ Saved actor to results/scenarios/s2_class3_90/actor.pt
✅ Saved critic to results/scenarios/s2_class3_90/critic.pt

[s2_class3_90] ✓ RL training complete


================================================================================
[s2_class3_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 2 - 90% Class 3
================================================================================
Loading model from: results/scenarios/s2_class3_90

✅ Loaded trained actor from results/scenarios/s2_class3_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s2_class3_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000586
Mean Latency: 0.058780 s
Mean Energy: 0.982 J
Final Battery: 2015.96 J
Success Rate: 99.8%
Offload Ratio: 0.966
================================================================================

[s2_class3_90] ✓ RL evaluation complete
  Mean QoE: -0.000586
  Final Battery: 2015.96 J
  Success Rate: 99.8%

[s2_class3_90] Time elapsed: 87.9 minutes


################################################################################
# SCENARIO 4/4: s2_random
################################################################################

Name: Scenario 2 - Random Distribution
Description: Communication failure 500-1000; equal task distribution
Task distribution: Class1=33%, Class2=34%, Class3=33%


================================================================================
[s2_random] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s2_random
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s2_random...
  Progress: 200/2000 (10.0%)

✅ Saved LOCAL results to results/scenarios/s2_random/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.097518
Mean Latency: 0.031114 s
Mean Energy: 1.991 J
Final Battery: 0.00 J
Success Rate: 5.4%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s2_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s2_random/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025003
Mean Latency: 0.553077 s
Mean Energy: 0.010 J
Final Battery: 3779.35 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s2_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s2_random/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.038602
Mean Latency: 0.588260 s
Mean Energy: 0.009 J
Final Battery: 3781.61 J
Success Rate: 61.4%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s2_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved RANDOM results to results/scenarios/s2_random/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.082788
Mean Latency: 0.330399 s
Mean Energy: 1.961 J
Final Battery: 0.00 J
Success Rate: 20.6%
Offload Ratio: 0.307
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s2_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s2_random/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.078811
Mean Latency: 0.548884 s
Mean Energy: 1.909 J
Final Battery: 0.00 J
Success Rate: 21.2%
Offload Ratio: 0.296
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.097518            0.00 J           5.4%
mec                -0.025003         3779.35 J          75.0%
cloud              -0.038602         3781.61 J          61.4%
random             -0.082788            0.00 J          20.6%
greedy_by_size     -0.078811            0.00 J          21.2%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s2_random/
================================================================================

[s2_random] ✓ Baselines complete


================================================================================
[s2_random] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3 MIG 1g.10gb
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: MIG-ba7859c1-a377-57cf-a799-b2d94d5b5277
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 2 - Random Distribution
================================================================================
Description: Communication failure 500-1000; equal task distribution
Task Distribution: Class1=33.0%, Class2=34.0%, Class3=33.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 6625 | return= -221.737 | avg_return(10)= -221.737 | battery=   0.00 J
Episode   10/200 | steps= 5328 | return=  -25.394 | avg_return(10)=  -66.585 | battery=   0.00 J
Episode   20/200 | steps= 5291 | return=  -23.491 | avg_return(10)=  -28.028 | battery=   0.00 J
Episode   30/200 | steps= 4979 | return=  -22.995 | avg_return(10)=  -22.973 | battery=   0.00 J
Episode   40/200 | steps= 5038 | return=  -12.313 | avg_return(10)=  -19.625 | battery=   0.00 J
Episode   50/200 | steps= 5117 | return=  -16.628 | avg_return(10)=  -17.133 | battery=   0.00 J
Episode   60/200 | steps= 4979 | return=  -23.489 | avg_return(10)=  -22.767 | battery=   0.00 J
Episode   70/200 | steps= 5304 | return=  -47.447 | avg_return(10)=  -50.456 | battery=   0.00 J
Episode   80/200 | steps= 5643 | return=  -57.682 | avg_return(10)=  -48.829 | battery=   0.00 J
Episode   90/200 | steps= 5476 | return=  -51.860 | avg_return(10)=  -44.611 | battery=   0.00 J
Episode  100/200 | steps= 5385 | return=  -53.756 | avg_return(10)=  -60.252 | battery=   0.00 J
Episode  110/200 | steps= 5450 | return=  -49.222 | avg_return(10)=  -42.920 | battery=   0.00 J
Episode  120/200 | steps= 5266 | return=  -33.400 | avg_return(10)=  -40.909 | battery=   0.00 J
Episode  130/200 | steps= 5270 | return=  -38.270 | avg_return(10)=  -41.889 | battery=   0.00 J
Episode  140/200 | steps= 5492 | return=  -52.081 | avg_return(10)=  -46.381 | battery=   0.00 J
Episode  150/200 | steps= 5479 | return=  -48.442 | avg_return(10)=  -42.934 | battery=   0.00 J
Episode  160/200 | steps= 5406 | return=  -40.007 | avg_return(10)= -605.340 | battery=   0.00 J
Episode  170/200 | steps= 5256 | return=  -29.648 | avg_return(10)=  -35.343 | battery=   0.00 J
Episode  180/200 | steps= 5576 | return=  -56.822 | avg_return(10)=  -37.814 | battery=   0.00 J
Episode  190/200 | steps= 5346 | return=  -51.233 | avg_return(10)=  -47.150 | battery=   0.00 J
Episode  200/200 | steps= 5431 | return=  -49.998 | avg_return(10)=  -43.212 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 2 - Random Distribution
Total episodes: 200
Final episode return: -49.998
Avg return (last 10): -43.212
Best episode return: -12.313
================================================================================

✅ Saved actor to results/scenarios/s2_random/actor.pt
✅ Saved critic to results/scenarios/s2_random/critic.pt

[s2_random] ✓ RL training complete


================================================================================
[s2_random] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 2 - Random Distribution
================================================================================
Loading model from: results/scenarios/s2_random

✅ Loaded trained actor from results/scenarios/s2_random/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s2_random/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000842
Mean Latency: 0.035240 s
Mean Energy: 0.996 J
Final Battery: 1987.94 J
Success Rate: 99.5%
Offload Ratio: 0.967
================================================================================

[s2_random] ✓ RL evaluation complete
  Mean QoE: -0.000842
  Final Battery: 1987.94 J
  Success Rate: 99.5%

[s2_random] Time elapsed: 72.1 minutes


================================================================================
GENERATING PLOTS
================================================================================

Generating Scenario 2 complete figure...

Generating Scenario 2 Complete Figure...

Processing s2_class1_90...
  ✓ s2_class1_90 plotted

Processing s2_class2_90...
  ✓ s2_class2_90 plotted

Processing s2_class3_90...
  ✓ s2_class3_90 plotted

Processing s2_random...
  ✓ s2_random plotted


✅ Scenario 2 figure saved to: results/scenarios/scenario_2_complete_figure.png

✓ Scenario 2 plots generated


================================================================================
ALL SCENARIOS COMPLETE
================================================================================
Total time: 334.9 minutes

RL Agent Results Summary:
--------------------------------------------------------------------------------
Scenario                 Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
s2_class1_90            -0.000414         3495.34 J          99.7%
s2_class2_90            -0.000416         3480.22 J          99.7%
s2_class3_90            -0.000586         2015.96 J          99.8%
s2_random               -0.000842         1987.94 J          99.5%
--------------------------------------------------------------------------------

Results saved to: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/results/scenarios/
================================================================================


End time: Fri Dec 19 03:48:09 EST 2025

=====================================
 Job Finished
=====================================

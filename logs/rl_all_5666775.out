====================================
 RL All Scenarios Job Started
 Job ID: 5666775
 Node: g24
 Time: Wed Dec 10 21:32:33 EST 2025
====================================

[CONFIG] Scenario Set: s1
[CONFIG] Episodes per scenario: 200
[CONFIG] Train: true
[CONFIG] Evaluate: true
[CONFIG] Plot: true

[SETUP] Loading modules...
[SETUP] Loaded modules:

Currently Loaded Modules:
  1) CCconfig            6) ucx/1.14.1            11) flexiblas/3.3.1
  2) gentoo/2023   (S)   7) libfabric/1.18.0      12) imkl/2023.2.0   (math)
  3) gcccore/.12.3 (H)   8) pmix/4.2.4            13) StdEnv/2023     (S)
  4) gcc/12.3      (t)   9) ucc/1.2.0             14) python/3.13.2   (t)
  5) hwloc/2.9.1        10) openmpi/4.1.5    (m)

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 


[SETUP] Working directory: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL

[SETUP] Activating virtual environment...
[SETUP] ✓ Virtual environment activated

=====================================
PYTHON & PYTORCH DIAGNOSTICS
=====================================
Python version: Python 3.13.2
Python path: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/bin/python
Pip version: pip 24.3.1 from /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/lib/python3.13/site-packages/pip (python 3.13)

[PYTORCH] Testing PyTorch installation...
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
GPU count: 1
GPU name: NVIDIA H100 80GB HBM3

=====================================
ENVIRONMENT VARIABLES
=====================================
SLURM_JOB_ID: 5666775
SLURM_JOB_NAME: rl_all_s1
SLURM_NODELIST: g24
SLURM_CPUS_PER_TASK: 4
SLURM_MEM_PER_NODE: 32768
CUDA_VISIBLE_DEVICES: 0

[SETUP] Setting CPU threading limits...
[SETUP] OMP_NUM_THREADS=4
[SETUP] MKL_NUM_THREADS=4

=====================================
GPU DIAGNOSTICS (nvidia-smi)
=====================================
Wed Dec 10 21:32:44 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   31C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

[GPU] ✓ GPU detected

=====================================
PYTHON PACKAGE VERIFICATION
=====================================
[PACKAGES] Checking required packages...
NumPy: 2.3.3
Pandas: 2.3.3
Matplotlib: 3.10.0
PyTorch: 2.9.0
All packages verified

=====================================
AVAILABLE SCENARIOS
=====================================

Available Scenarios:
================================================================================

** SCENARIO 1: MEC Unavailability **

[s1_base]
  Name: Scenario 1 - Base
  Description: MEC unavailable during timesteps 500-750 and 1250-1500
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s1_class1_90]
  Name: Scenario 1 - 90% Class 1
  Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s1_class2_90]
  Name: Scenario 1 - 90% Class 2
  Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s1_class3_90]
  Name: Scenario 1 - 90% Class 3
  Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s1_random]
  Name: Scenario 1 - Random Distribution
  Description: MEC unavailable 500-750, 1250-1500; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

--------------------------------------------------------------------------------

** SCENARIO 2: Communication Failure **

[s2_base]
  Name: Scenario 2 - Base
  Description: MEC stable, communication failure 500-1000
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s2_class1_90]
  Name: Scenario 2 - 90% Class 1
  Description: Communication failure 500-1000; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s2_class2_90]
  Name: Scenario 2 - 90% Class 2
  Description: Communication failure 500-1000; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s2_class3_90]
  Name: Scenario 2 - 90% Class 3
  Description: Communication failure 500-1000; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s2_random]
  Name: Scenario 2 - Random Distribution
  Description: Communication failure 500-1000; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

================================================================================

Predefined Scenario Sets:
================================================================================

s1:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random

s1_base:
  - s1_base

s2:
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

s2_base:
  - s2_base

all:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

================================================================================

=====================================
RUNNING ALL SCENARIOS: s1
=====================================
Start time: Wed Dec 10 21:32:53 EST 2025

[CMD] python -u run_all_scenarios.py --scenario-set s1 --episodes 200 --all --train --eval --plot


================================================================================
RUNNING ALL SCENARIOS
================================================================================
Scenarios to run: ['s1_class1_90', 's1_class2_90', 's1_class3_90', 's1_random']
Training episodes: 200
Train RL: True
Evaluate RL: True
Run baselines: True
Plot: True
Device: auto
================================================================================


################################################################################
# SCENARIO 1/4: s1_class1_90
################################################################################

Name: Scenario 1 - 90% Class 1
Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
Task distribution: Class1=90%, Class2=5%, Class3=5%


================================================================================
[s1_class1_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class1_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved LOCAL results to results/scenarios/s1_class1_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.055595
Mean Latency: 0.030483 s
Mean Energy: 1.951 J
Final Battery: 0.00 J
Success Rate: 49.4%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class1_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 116.839799 s
Mean Energy: 0.003 J
Final Battery: 3793.53 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class1_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000001
Mean Latency: 0.004643 s
Mean Energy: 0.004 J
Final Battery: 3791.25 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s1_class1_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.008717
Mean Latency: 29.341569 s
Mean Energy: 1.424 J
Final Battery: 952.67 J
Success Rate: 92.0%
Offload Ratio: 0.652
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.055595            0.00 J          49.4%
mec                -0.025001         3793.53 J          75.0%
cloud              -0.000001         3791.25 J         100.0%
random             -0.008717          952.67 J          92.0%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class1_90/
================================================================================

[s1_class1_90] ✓ Baselines complete


================================================================================
[s1_class1_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.00 GB
  Memory reserved: 0.00 GB
  Max memory allocated: 0.00 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 1
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
Task Distribution: Class1=90.0%, Class2=5.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 3871 | return=   -7.492 | avg_return(10)=   -7.492 | battery=   0.00 J
Episode   10/200 | steps= 7190 | return=  -10.116 | avg_return(10)=  -21.356 | battery=   0.00 J
Episode   20/200 | steps= 6818 | return=   -8.799 | avg_return(10)=   -9.493 | battery=   0.00 J
Episode   30/200 | steps= 7171 | return=   -9.236 | avg_return(10)=   -9.273 | battery=   0.00 J
Episode   40/200 | steps= 6779 | return=  -13.098 | avg_return(10)=   -9.777 | battery=   0.00 J
Episode   50/200 | steps= 6567 | return=   -6.484 | avg_return(10)=  -10.108 | battery=   0.00 J
Episode   60/200 | steps= 6466 | return=   -8.449 | avg_return(10)=   -9.825 | battery=   0.00 J
Episode   70/200 | steps= 6891 | return=  -15.308 | avg_return(10)=   -9.961 | battery=   0.00 J
Episode   80/200 | steps= 7367 | return=  -12.395 | avg_return(10)=   -9.640 | battery=   0.00 J
Episode   90/200 | steps= 7240 | return=   -8.306 | avg_return(10)=  -10.456 | battery=   0.00 J
Episode  100/200 | steps= 7726 | return=   -8.252 | avg_return(10)=   -9.260 | battery=   0.00 J
Episode  110/200 | steps= 6745 | return=  -11.562 | avg_return(10)=   -8.632 | battery=   0.00 J
Episode  120/200 | steps= 6893 | return=   -8.942 | avg_return(10)=   -8.954 | battery=   0.00 J
Episode  130/200 | steps= 6795 | return=   -8.250 | avg_return(10)=   -9.354 | battery=   0.00 J
Episode  140/200 | steps= 7705 | return=   -8.290 | avg_return(10)=   -8.623 | battery=   0.00 J
Episode  150/200 | steps= 6114 | return=   -7.655 | avg_return(10)=   -9.355 | battery=   0.00 J
Episode  160/200 | steps= 7668 | return=   -9.713 | avg_return(10)=   -9.819 | battery=   0.00 J
Episode  170/200 | steps= 6994 | return=  -10.698 | avg_return(10)=  -11.199 | battery=   0.00 J
Episode  180/200 | steps= 7113 | return=   -9.928 | avg_return(10)=  -18.983 | battery=   0.00 J
Episode  190/200 | steps= 6648 | return=   -7.963 | avg_return(10)=-1440.981 | battery=   0.00 J
Episode  200/200 | steps= 7443 | return=   -8.328 | avg_return(10)=   -8.736 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 1
Total episodes: 200
Final episode return: -8.328
Avg return (last 10): -8.736
Best episode return: -5.946
================================================================================

✅ Saved actor to results/scenarios/s1_class1_90/actor.pt
✅ Saved critic to results/scenarios/s1_class1_90/critic.pt

[s1_class1_90] ✓ RL training complete


================================================================================
[s1_class1_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 1
================================================================================
Loading model from: results/scenarios/s1_class1_90

✅ Loaded trained actor from results/scenarios/s1_class1_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class1_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000442
Mean Latency: 0.022284 s
Mean Energy: 1.172 J
Final Battery: 1636.60 J
Success Rate: 100.0%
Offload Ratio: 0.585
================================================================================

[s1_class1_90] ✓ RL evaluation complete
  Mean QoE: -0.000442
  Final Battery: 1636.60 J
  Success Rate: 100.0%

[s1_class1_90] Time elapsed: 82.7 minutes


################################################################################
# SCENARIO 2/4: s1_class2_90
################################################################################

Name: Scenario 1 - 90% Class 2
Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
Task distribution: Class1=5%, Class2=90%, Class3=5%


================================================================================
[s1_class2_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class2_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)

✅ Saved LOCAL results to results/scenarios/s1_class2_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.065297
Mean Latency: 0.030660 s
Mean Energy: 1.962 J
Final Battery: 0.00 J
Success Rate: 39.1%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class2_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 145.457810 s
Mean Energy: 0.004 J
Final Battery: 3792.20 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class2_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000001
Mean Latency: 0.005658 s
Mean Energy: 0.005 J
Final Battery: 3789.35 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s1_class2_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.008921
Mean Latency: 48.897836 s
Mean Energy: 1.517 J
Final Battery: 766.26 J
Success Rate: 91.8%
Offload Ratio: 0.679
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.065297            0.00 J          39.1%
mec                -0.025001         3792.20 J          75.0%
cloud              -0.000001         3789.35 J         100.0%
random             -0.008921          766.26 J          91.8%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class2_90/
================================================================================

[s1_class2_90] ✓ Baselines complete


================================================================================
[s1_class2_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 2
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
Task Distribution: Class1=5.0%, Class2=90.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 3057 | return=   -7.354 | avg_return(10)=   -7.354 | battery=   0.00 J
Episode   10/200 | steps= 7058 | return=   -9.562 | avg_return(10)=  -12.335 | battery=   0.00 J
Episode   20/200 | steps= 6175 | return=  -92.753 | avg_return(10)=  -29.482 | battery=   0.00 J
Episode   30/200 | steps= 7580 | return=   -7.099 | avg_return(10)=  -10.692 | battery=   0.00 J
Episode   40/200 | steps= 7619 | return=   -9.590 | avg_return(10)=  -13.084 | battery=   0.00 J
Episode   50/200 | steps= 6747 | return=   -9.346 | avg_return(10)=  -14.476 | battery=   0.00 J
Episode   60/200 | steps= 8099 | return=   -7.742 | avg_return(10)=   -9.007 | battery=   0.00 J
Episode   70/200 | steps= 7576 | return=  -19.631 | avg_return(10)=  -10.326 | battery=   0.00 J
Episode   80/200 | steps= 7668 | return=  -10.982 | avg_return(10)=   -8.429 | battery=   0.00 J
Episode   90/200 | steps= 9468 | return=   -8.122 | avg_return(10)=   -8.195 | battery=   0.00 J
Episode  100/200 | steps= 9481 | return=  -10.617 | avg_return(10)=   -9.675 | battery=   0.00 J
Episode  110/200 | steps= 7058 | return=   -7.879 | avg_return(10)=  -10.232 | battery=   0.00 J
Episode  120/200 | steps= 6954 | return=   -9.964 | avg_return(10)=   -8.932 | battery=   0.00 J
Episode  130/200 | steps= 7490 | return=   -7.226 | avg_return(10)=   -8.765 | battery=   0.00 J
Episode  140/200 | steps= 8088 | return=   -8.160 | avg_return(10)=  -20.990 | battery=   0.00 J
Episode  150/200 | steps= 8045 | return=   -8.689 | avg_return(10)=   -8.920 | battery=   0.00 J
Episode  160/200 | steps= 7529 | return=   -8.015 | avg_return(10)=   -8.644 | battery=   0.00 J
Episode  170/200 | steps= 8004 | return=   -7.595 | avg_return(10)=   -9.505 | battery=   0.00 J
Episode  180/200 | steps= 8248 | return=   -7.403 | avg_return(10)=  -14.480 | battery=   0.00 J
Episode  190/200 | steps= 7990 | return=  -15.812 | avg_return(10)=  -10.584 | battery=   0.00 J
Episode  200/200 | steps= 7613 | return=  -10.706 | avg_return(10)=   -8.219 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 2
Total episodes: 200
Final episode return: -10.706
Avg return (last 10): -8.219
Best episode return: -5.517
================================================================================

✅ Saved actor to results/scenarios/s1_class2_90/actor.pt
✅ Saved critic to results/scenarios/s1_class2_90/critic.pt

[s1_class2_90] ✓ RL training complete


================================================================================
[s1_class2_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 2
================================================================================
Loading model from: results/scenarios/s1_class2_90

✅ Loaded trained actor from results/scenarios/s1_class2_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class2_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000322
Mean Latency: 0.020515 s
Mean Energy: 0.948 J
Final Battery: 2084.55 J
Success Rate: 100.0%
Offload Ratio: 0.751
================================================================================

[s1_class2_90] ✓ RL evaluation complete
  Mean QoE: -0.000322
  Final Battery: 2084.55 J
  Success Rate: 100.0%

[s1_class2_90] Time elapsed: 90.3 minutes


################################################################################
# SCENARIO 3/4: s1_class3_90
################################################################################

Name: Scenario 1 - 90% Class 3
Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
Task distribution: Class1=5%, Class2=5%, Class3=90%


================================================================================
[s1_class3_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class3_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class3_90...

✅ Saved LOCAL results to results/scenarios/s1_class3_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.095422
Mean Latency: 0.031143 s
Mean Energy: 1.993 J
Final Battery: 0.00 J
Success Rate: 7.2%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class3_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025006
Mean Latency: 1383.679701 s
Mean Energy: 0.023 J
Final Battery: 3754.16 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class3_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000008
Mean Latency: 0.032259 s
Mean Energy: 0.030 J
Final Battery: 3739.22 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class3_90...
  Progress: 200/2000 (10.0%)

✅ Saved RANDOM results to results/scenarios/s1_class3_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.084189
Mean Latency: 0.035867 s
Mean Energy: 1.988 J
Final Battery: 0.00 J
Success Rate: 18.9%
Offload Ratio: 0.119
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.095422            0.00 J           7.2%
mec                -0.025006         3754.16 J          75.0%
cloud              -0.000008         3739.22 J         100.0%
random             -0.084189            0.00 J          18.9%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class3_90/
================================================================================

[s1_class3_90] ✓ Baselines complete


================================================================================
[s1_class3_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 3
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
Task Distribution: Class1=5.0%, Class2=5.0%, Class3=90.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps=  476 | return=   -5.265 | avg_return(10)=   -5.265 | battery=   0.00 J
Episode   10/200 | steps=10041 | return=  -10.139 | avg_return(10)=  -10.230 | battery=   0.00 J
Episode   20/200 | steps=15071 | return=-3638.308 | avg_return(10)= -373.224 | battery=   0.00 J
Episode   30/200 | steps= 8879 | return=   -7.027 | avg_return(10)=   -9.882 | battery=   0.00 J
Episode   40/200 | steps= 8016 | return=  -43.783 | avg_return(10)=  -19.827 | battery=   0.00 J
Episode   50/200 | steps=15960 | return= -317.514 | avg_return(10)=  -42.166 | battery=   0.00 J
Episode   60/200 | steps= 7994 | return=  -13.507 | avg_return(10)=  -13.642 | battery=   0.00 J
Episode   70/200 | steps= 8914 | return=  -14.255 | avg_return(10)=  -11.016 | battery=   0.00 J
Episode   80/200 | steps=10500 | return=  -10.919 | avg_return(10)=  -10.489 | battery=   0.00 J
Episode   90/200 | steps=10021 | return=   -6.666 | avg_return(10)=  -10.147 | battery=   0.00 J
Episode  100/200 | steps= 7560 | return=   -6.968 | avg_return(10)=  -11.385 | battery=   0.00 J
Episode  110/200 | steps= 7740 | return=   -7.509 | avg_return(10)=  -11.842 | battery=   0.00 J
Episode  120/200 | steps= 8346 | return=  -11.126 | avg_return(10)=  -12.643 | battery=   0.00 J
Episode  130/200 | steps= 9034 | return=   -5.799 | avg_return(10)=  -10.427 | battery=   0.00 J
Episode  140/200 | steps= 8452 | return=   -7.587 | avg_return(10)=  -10.485 | battery=   0.00 J
Episode  150/200 | steps= 7787 | return=  -21.751 | avg_return(10)=  -11.999 | battery=   0.00 J
Episode  160/200 | steps= 8036 | return=  -11.126 | avg_return(10)=  -12.621 | battery=   0.00 J
Episode  170/200 | steps=10403 | return= -129.357 | avg_return(10)=  -24.956 | battery=   0.00 J
Episode  180/200 | steps= 8295 | return=   -9.947 | avg_return(10)=  -10.858 | battery=   0.00 J
Episode  190/200 | steps= 8911 | return=  -12.407 | avg_return(10)=  -19.046 | battery=   0.00 J
Episode  200/200 | steps= 8642 | return=  -12.851 | avg_return(10)=  -16.139 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 3
Total episodes: 200
Final episode return: -12.851
Avg return (last 10): -16.139
Best episode return: -4.973
================================================================================

✅ Saved actor to results/scenarios/s1_class3_90/actor.pt
✅ Saved critic to results/scenarios/s1_class3_90/critic.pt

[s1_class3_90] ✓ RL training complete


================================================================================
[s1_class3_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 3
================================================================================
Loading model from: results/scenarios/s1_class3_90

✅ Loaded trained actor from results/scenarios/s1_class3_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class3_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000621
Mean Latency: 0.058233 s
Mean Energy: 1.425 J
Final Battery: 1129.43 J
Success Rate: 100.0%
Offload Ratio: 0.930
================================================================================

[s1_class3_90] ✓ RL evaluation complete
  Mean QoE: -0.000621
  Final Battery: 1129.43 J
  Success Rate: 100.0%

[s1_class3_90] Time elapsed: 116.4 minutes


################################################################################
# SCENARIO 4/4: s1_random
################################################################################

Name: Scenario 1 - Random Distribution
Description: MEC unavailable 500-750, 1250-1500; equal task distribution
Task distribution: Class1=33%, Class2=34%, Class3=33%


================================================================================
[s1_random] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_random
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_random...
  Progress: 200/2000 (10.0%)

✅ Saved LOCAL results to results/scenarios/s1_random/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.092816
Mean Latency: 0.031294 s
Mean Energy: 2.003 J
Final Battery: 0.00 J
Success Rate: 14.4%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_random/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025003
Mean Latency: 529.344669 s
Mean Energy: 0.010 J
Final Battery: 3780.08 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_random/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.000003
Mean Latency: 0.013533 s
Mean Energy: 0.013 J
Final Battery: 3774.51 J
Success Rate: 100.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved RANDOM results to results/scenarios/s1_random/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.058409
Mean Latency: 74.242903 s
Mean Energy: 1.958 J
Final Battery: 0.00 J
Success Rate: 44.6%
Offload Ratio: 0.330
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.092816            0.00 J          14.4%
mec                -0.025003         3780.08 J          75.0%
cloud              -0.000003         3774.51 J         100.0%
random             -0.058409            0.00 J          44.6%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_random/
================================================================================

[s1_random] ✓ Baselines complete


================================================================================
[s1_random] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - Random Distribution
================================================================================
Description: MEC unavailable 500-750, 1250-1500; equal task distribution
Task Distribution: Class1=33.0%, Class2=34.0%, Class3=33.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 1662 | return=   -8.501 | avg_return(10)=   -8.501 | battery=   0.00 J
Episode   10/200 | steps= 6343 | return=  -12.471 | avg_return(10)=  -13.629 | battery=   0.00 J
Episode   20/200 | steps= 7589 | return=   -8.574 | avg_return(10)=  -12.570 | battery=   0.00 J
Episode   30/200 | steps= 7851 | return=  -13.133 | avg_return(10)=   -9.348 | battery=   0.00 J
Episode   40/200 | steps= 6843 | return=   -9.123 | avg_return(10)=  -11.439 | battery=   0.00 J
Episode   50/200 | steps= 6031 | return=  -20.650 | avg_return(10)=  -12.986 | battery=   0.00 J
Episode   60/200 | steps= 8122 | return=  -13.924 | avg_return(10)=  -11.001 | battery=   0.00 J
Episode   70/200 | steps= 6587 | return=   -9.455 | avg_return(10)=  -10.994 | battery=   0.00 J
Episode   80/200 | steps= 7546 | return=  -14.821 | avg_return(10)=  -10.611 | battery=   0.00 J
Episode   90/200 | steps= 6796 | return=  -12.732 | avg_return(10)=   -9.272 | battery=   0.00 J
Episode  100/200 | steps= 7559 | return=   -8.602 | avg_return(10)=  -24.674 | battery=   0.00 J
Episode  110/200 | steps= 7520 | return=   -5.428 | avg_return(10)=  -16.346 | battery=   0.00 J
Episode  120/200 | steps= 7968 | return=   -8.043 | avg_return(10)=  -11.897 | battery=   0.00 J
Episode  130/200 | steps= 7397 | return=  -24.871 | avg_return(10)=  -11.113 | battery=   0.00 J
Episode  140/200 | steps= 7694 | return=   -8.087 | avg_return(10)=  -10.950 | battery=   0.00 J
Episode  150/200 | steps= 5283 | return=   -7.065 | avg_return(10)=   -8.866 | battery=   0.00 J
Episode  160/200 | steps= 8034 | return=   -9.731 | avg_return(10)=  -11.017 | battery=   0.00 J
Episode  170/200 | steps= 7291 | return=   -8.388 | avg_return(10)=  -40.503 | battery=   0.00 J
Episode  180/200 | steps= 7518 | return=  -48.798 | avg_return(10)=  -19.610 | battery=   0.00 J
Episode  190/200 | steps= 8340 | return=   -8.728 | avg_return(10)=  -11.267 | battery=   0.00 J
Episode  200/200 | steps= 8217 | return=   -8.192 | avg_return(10)=  -10.209 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - Random Distribution
Total episodes: 200
Final episode return: -8.192
Avg return (last 10): -10.209
Best episode return: -5.428
================================================================================

✅ Saved actor to results/scenarios/s1_random/actor.pt
✅ Saved critic to results/scenarios/s1_random/critic.pt

[s1_random] ✓ RL training complete


================================================================================
[s1_random] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - Random Distribution
================================================================================
Loading model from: results/scenarios/s1_random

✅ Loaded trained actor from results/scenarios/s1_random/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_random/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000534
Mean Latency: 0.035521 s
Mean Energy: 1.312 J
Final Battery: 1356.48 J
Success Rate: 100.0%
Offload Ratio: 0.752
================================================================================

[s1_random] ✓ RL evaluation complete
  Mean QoE: -0.000534
  Final Battery: 1356.48 J
  Success Rate: 100.0%

[s1_random] Time elapsed: 83.5 minutes


================================================================================
GENERATING PLOTS
================================================================================

Generating Scenario 1 complete figure...

Plotting Class 1 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps

Plotting Class 2 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps

Plotting Class 3 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps

Plotting Random (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps

✅ Figure saved to: results/scenarios/scenario_1_complete_figure.png
✓ Scenario 1 plots generated


================================================================================
ALL SCENARIOS COMPLETE
================================================================================
Total time: 373.0 minutes

RL Agent Results Summary:
--------------------------------------------------------------------------------
Scenario                 Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
s1_class1_90            -0.000442         1636.60 J         100.0%
s1_class2_90            -0.000322         2084.55 J         100.0%
s1_class3_90            -0.000621         1129.43 J         100.0%
s1_random               -0.000534         1356.48 J         100.0%
--------------------------------------------------------------------------------

Results saved to: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/results/scenarios/
================================================================================


End time: Thu Dec 11 03:45:54 EST 2025

=====================================
✓ ALL SCENARIOS COMPLETED SUCCESSFULLY
=====================================

Results location: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/results/scenarios/
Logs location: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/logs/

=====================================
OUTPUT FILES
=====================================
Scenario directories:
results/scenarios/s1_class1_90/
results/scenarios/s1_class2_90/
results/scenarios/s1_class3_90/
results/scenarios/s1_random/
results/scenarios/s2_class1_90/
results/scenarios/s2_class2_90/
results/scenarios/s2_class3_90/
results/scenarios/s2_random/

CSV files:
results/scenarios/s1_class1_90/cloud_metrics.csv
results/scenarios/s1_class1_90/local_metrics.csv
results/scenarios/s1_class1_90/mec_metrics.csv
results/scenarios/s1_class1_90/random_metrics.csv
results/scenarios/s1_class1_90/rl_agent_metrics.csv
results/scenarios/s1_class2_90/cloud_metrics.csv
results/scenarios/s1_class2_90/local_metrics.csv
results/scenarios/s1_class2_90/mec_metrics.csv
results/scenarios/s1_class2_90/random_metrics.csv
results/scenarios/s1_class2_90/rl_agent_metrics.csv

Model files:
results/scenarios/s1_class1_90/actor.pt
results/scenarios/s1_class1_90/critic.pt
results/scenarios/s1_class2_90/actor.pt
results/scenarios/s1_class2_90/critic.pt
results/scenarios/s1_class3_90/actor.pt
results/scenarios/s1_class3_90/critic.pt
results/scenarios/s1_random/actor.pt
results/scenarios/s1_random/critic.pt
results/scenarios/s2_class1_90/actor.pt
results/scenarios/s2_class1_90/critic.pt

Plot files:
results/scenarios/scenario_1_complete_figure.png
results/scenarios/scenario_2_complete_figure.png

=====================================
 Job Finished
=====================================

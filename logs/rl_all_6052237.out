====================================
 RL All Scenarios Job Started
 Job ID: 6052237
 Node: g24
 Time: Fri Dec 19 12:14:30 EST 2025
====================================

[CONFIG] Scenario Set: s1
[CONFIG] Episodes per scenario: 200
[CONFIG] Train: true
[CONFIG] Evaluate: true
[CONFIG] Plot: true

[SETUP] Loading modules...
[SETUP] Loaded modules:

Currently Loaded Modules:
  1) CCconfig            6) ucx/1.14.1            11) flexiblas/3.3.1
  2) gentoo/2023   (S)   7) libfabric/1.18.0      12) imkl/2023.2.0   (math)
  3) gcccore/.12.3 (H)   8) pmix/4.2.4            13) StdEnv/2023     (S)
  4) gcc/12.3      (t)   9) ucc/1.2.0             14) python/3.13.2   (t)
  5) hwloc/2.9.1        10) openmpi/4.1.5    (m)

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 


[SETUP] Working directory: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL

[SETUP] Activating virtual environment...
[SETUP] ✓ Virtual environment activated

=====================================
PYTHON & PYTORCH DIAGNOSTICS
=====================================
Python version: Python 3.13.2
Python path: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/bin/python
Pip version: pip 24.3.1 from /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/.venv/lib/python3.13/site-packages/pip (python 3.13)

[PYTORCH] Testing PyTorch installation...
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
GPU count: 1
GPU name: NVIDIA H100 80GB HBM3

=====================================
ENVIRONMENT VARIABLES
=====================================
SLURM_JOB_ID: 6052237
SLURM_JOB_NAME: rl_all_s1
SLURM_NODELIST: g24
SLURM_CPUS_PER_TASK: 4
SLURM_MEM_PER_NODE: 32768
CUDA_VISIBLE_DEVICES: 0

[SETUP] Setting CPU threading limits...
[SETUP] OMP_NUM_THREADS=4
[SETUP] MKL_NUM_THREADS=4

=====================================
GPU DIAGNOSTICS (nvidia-smi)
=====================================
Fri Dec 19 12:14:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   32C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

[GPU] ✓ GPU detected

=====================================
PYTHON PACKAGE VERIFICATION
=====================================
[PACKAGES] Checking required packages...
NumPy: 2.3.3
Pandas: 2.3.3
Matplotlib: 3.10.0
PyTorch: 2.9.0
All packages verified

=====================================
AVAILABLE SCENARIOS
=====================================

Available Scenarios:
================================================================================

** SCENARIO 1: MEC Unavailability **

[s1_base]
  Name: Scenario 1 - Base
  Description: MEC unavailable during timesteps 500-750 and 1250-1500
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s1_class1_90]
  Name: Scenario 1 - 90% Class 1
  Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s1_class2_90]
  Name: Scenario 1 - 90% Class 2
  Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s1_class3_90]
  Name: Scenario 1 - 90% Class 3
  Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s1_random]
  Name: Scenario 1 - Random Distribution
  Description: MEC unavailable 500-750, 1250-1500; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

--------------------------------------------------------------------------------

** SCENARIO 2: Communication Failure **

[s2_base]
  Name: Scenario 2 - Base
  Description: MEC stable, communication failure 500-1000
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

[s2_class1_90]
  Name: Scenario 2 - 90% Class 1
  Description: Communication failure 500-1000; 90% delay-sensitive tasks
  Task Distribution: Class1=90%, Class2=5%, Class3=5%

[s2_class2_90]
  Name: Scenario 2 - 90% Class 2
  Description: Communication failure 500-1000; 90% energy-sensitive tasks
  Task Distribution: Class1=5%, Class2=90%, Class3=5%

[s2_class3_90]
  Name: Scenario 2 - 90% Class 3
  Description: Communication failure 500-1000; 90% insensitive tasks
  Task Distribution: Class1=5%, Class2=5%, Class3=90%

[s2_random]
  Name: Scenario 2 - Random Distribution
  Description: Communication failure 500-1000; equal task distribution
  Task Distribution: Class1=33%, Class2=34%, Class3=33%

================================================================================

Predefined Scenario Sets:
================================================================================

s1:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random

s1_base:
  - s1_base

s2:
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

s2_base:
  - s2_base

all:
  - s1_class1_90
  - s1_class2_90
  - s1_class3_90
  - s1_random
  - s2_class1_90
  - s2_class2_90
  - s2_class3_90
  - s2_random

================================================================================

=====================================
RUNNING ALL SCENARIOS: s1
=====================================
Start time: Fri Dec 19 12:14:45 EST 2025

[CMD] python -u run_all_scenarios.py --scenario-set s1 --episodes 200 --all --train --eval --plot


================================================================================
RUNNING ALL SCENARIOS
================================================================================
Scenarios to run: ['s1_class1_90', 's1_class2_90', 's1_class3_90', 's1_random']
Training episodes: 200
Train RL: True
Evaluate RL: True
Run baselines: True
Plot: True
Device: auto
================================================================================


################################################################################
# SCENARIO 1/4: s1_class1_90
################################################################################

Name: Scenario 1 - 90% Class 1
Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
Task distribution: Class1=90%, Class2=5%, Class3=5%


================================================================================
[s1_class1_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class1_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved LOCAL results to results/scenarios/s1_class1_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.098437
Mean Latency: 0.030527 s
Mean Energy: 1.954 J
Final Battery: 0.00 J
Success Rate: 2.6%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class1_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 0.129404 s
Mean Energy: 0.004 J
Final Battery: 3792.97 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class1_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.048501
Mean Latency: 0.014703 s
Mean Energy: 0.004 J
Final Battery: 3791.13 J
Success Rate: 51.5%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s1_class1_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.055694
Mean Latency: 0.059275 s
Mean Energy: 1.328 J
Final Battery: 1143.68 J
Success Rate: 44.5%
Offload Ratio: 0.664
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_class1_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_class1_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.097551
Mean Latency: 0.109337 s
Mean Energy: 1.924 J
Final Battery: 0.00 J
Success Rate: 2.5%
Offload Ratio: 0.037
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.098437            0.00 J           2.6%
mec                -0.025001         3792.97 J          75.0%
cloud              -0.048501         3791.13 J          51.5%
random             -0.055694         1143.68 J          44.5%
greedy_by_size     -0.097551            0.00 J           2.5%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class1_90/
================================================================================

[s1_class1_90] ✓ Baselines complete


================================================================================
[s1_class1_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.00 GB
  Memory reserved: 0.00 GB
  Max memory allocated: 0.00 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 1
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% delay-sensitive tasks
Task Distribution: Class1=90.0%, Class2=5.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps=20141 | return= -390.334 | avg_return(10)= -390.334 | battery=2291.30 J
Episode   10/200 | steps=20118 | return= -261.117 | avg_return(10)= -280.079 | battery=1118.13 J
Episode   20/200 | steps=19950 | return= -260.087 | avg_return(10)= -259.520 | battery= 880.31 J
Episode   30/200 | steps=20118 | return= -268.486 | avg_return(10)= -261.360 | battery= 482.34 J
Episode   40/200 | steps=20034 | return= -259.857 | avg_return(10)= -259.018 | battery=1292.04 J
Episode   50/200 | steps=20133 | return= -259.036 | avg_return(10)= -261.402 | battery= 776.47 J
Episode   60/200 | steps=20202 | return= -258.707 | avg_return(10)= -261.095 | battery= 704.36 J
Episode   70/200 | steps=20144 | return= -263.308 | avg_return(10)= -263.363 | battery= 364.03 J
Episode   80/200 | steps=19818 | return= -264.357 | avg_return(10)= -263.815 | battery=1110.33 J
Episode   90/200 | steps=19932 | return= -266.877 | avg_return(10)= -259.135 | battery=1034.46 J
Episode  100/200 | steps=19991 | return= -259.590 | avg_return(10)= -262.856 | battery= 817.32 J
Episode  110/200 | steps=20268 | return= -265.844 | avg_return(10)= -262.992 | battery= 329.02 J
Episode  120/200 | steps=19778 | return= -267.419 | avg_return(10)= -267.777 | battery= 946.63 J
Episode  130/200 | steps=20202 | return= -282.673 | avg_return(10)= -267.940 | battery= 455.09 J
Episode  140/200 | steps=20370 | return= -280.307 | avg_return(10)= -274.049 | battery= 283.30 J
Episode  150/200 | steps=19877 | return= -280.003 | avg_return(10)= -277.022 | battery= 813.25 J
Episode  160/200 | steps=20040 | return= -264.556 | avg_return(10)= -270.959 | battery= 112.93 J
Episode  170/200 | steps=19893 | return= -271.930 | avg_return(10)= -271.241 | battery= 738.34 J
Episode  180/200 | steps=20181 | return= -273.122 | avg_return(10)= -267.512 | battery=1092.59 J
Episode  190/200 | steps=19691 | return= -259.875 | avg_return(10)= -265.045 | battery= 709.19 J
Episode  200/200 | steps=20070 | return= -267.197 | avg_return(10)= -264.387 | battery=1570.53 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 1
Total episodes: 200
Final episode return: -267.197
Avg return (last 10): -264.387
Best episode return: -250.278
================================================================================

✅ Saved actor to results/scenarios/s1_class1_90/actor.pt
✅ Saved critic to results/scenarios/s1_class1_90/critic.pt

[s1_class1_90] ✓ RL training complete


================================================================================
[s1_class1_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 1
================================================================================
Loading model from: results/scenarios/s1_class1_90

✅ Loaded trained actor from results/scenarios/s1_class1_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class1_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000746
Mean Latency: 0.010342 s
Mean Energy: 0.177 J
Final Battery: 3625.32 J
Success Rate: 99.3%
Offload Ratio: 0.994
================================================================================

[s1_class1_90] ✓ RL evaluation complete
  Mean QoE: -0.000746
  Final Battery: 3625.32 J
  Success Rate: 99.3%

[s1_class1_90] Time elapsed: 230.4 minutes


################################################################################
# SCENARIO 2/4: s1_class2_90
################################################################################

Name: Scenario 1 - 90% Class 2
Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
Task distribution: Class1=5%, Class2=90%, Class3=5%


================================================================================
[s1_class2_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class2_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved LOCAL results to results/scenarios/s1_class2_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.098915
Mean Latency: 0.030591 s
Mean Energy: 1.958 J
Final Battery: 0.00 J
Success Rate: 1.7%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class2_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025001
Mean Latency: 0.190496 s
Mean Energy: 0.004 J
Final Battery: 3792.12 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class2_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.002501
Mean Latency: 0.015705 s
Mean Energy: 0.005 J
Final Battery: 3789.25 J
Success Rate: 97.5%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved RANDOM results to results/scenarios/s1_class2_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.041257
Mean Latency: 0.093823 s
Mean Energy: 1.837 J
Final Battery: 125.84 J
Success Rate: 59.5%
Offload Ratio: 0.663
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_class2_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_class2_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.097751
Mean Latency: 0.068584 s
Mean Energy: 1.942 J
Final Battery: 0.00 J
Success Rate: 2.2%
Offload Ratio: 0.029
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.098915            0.00 J           1.7%
mec                -0.025001         3792.12 J          75.0%
cloud              -0.002501         3789.25 J          97.5%
random             -0.041257          125.84 J          59.5%
greedy_by_size     -0.097751            0.00 J           2.2%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class2_90/
================================================================================

[s1_class2_90] ✓ Baselines complete


================================================================================
[s1_class2_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 2
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% energy-sensitive tasks
Task Distribution: Class1=5.0%, Class2=90.0%, Class3=5.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps=19859 | return=  -69.070 | avg_return(10)=  -69.070 | battery=2494.64 J
Episode   10/200 | steps=19915 | return=  -20.993 | avg_return(10)=  -26.290 | battery=2751.90 J
Episode   20/200 | steps=20045 | return=  -19.587 | avg_return(10)=  -21.447 | battery=1084.43 J
Episode   30/200 | steps=20025 | return=  -21.131 | avg_return(10)=  -21.895 | battery= 482.18 J
Episode   40/200 | steps=19628 | return=  -22.241 | avg_return(10)=  -21.417 | battery= 615.69 J
Episode   50/200 | steps=19873 | return=  -22.468 | avg_return(10)=  -21.658 | battery= 616.03 J
Episode   60/200 | steps=20055 | return=  -19.066 | avg_return(10)=  -21.107 | battery= 697.06 J
Episode   70/200 | steps=19966 | return=  -20.194 | avg_return(10)=  -20.622 | battery= 670.49 J
Episode   80/200 | steps=19874 | return=  -20.145 | avg_return(10)=  -21.027 | battery= 516.06 J
Episode   90/200 | steps=20268 | return=  -21.948 | avg_return(10)=  -21.076 | battery= 518.63 J
Episode  100/200 | steps=19982 | return=  -19.698 | avg_return(10)=  -20.486 | battery= 683.55 J
Episode  110/200 | steps=20122 | return=  -22.373 | avg_return(10)=  -20.840 | battery= 390.29 J
Episode  120/200 | steps=19709 | return=  -20.226 | avg_return(10)=  -20.975 | battery= 468.64 J
Episode  130/200 | steps=20075 | return=  -19.216 | avg_return(10)=  -20.619 | battery= 584.79 J
Episode  140/200 | steps=19746 | return=  -21.649 | avg_return(10)=  -20.794 | battery= 560.62 J
Episode  150/200 | steps=20157 | return=  -20.659 | avg_return(10)=  -20.794 | battery= 630.01 J
Episode  160/200 | steps=19903 | return=  -17.110 | avg_return(10)=  -20.206 | battery= 926.69 J
Episode  170/200 | steps=20020 | return=  -21.237 | avg_return(10)=  -20.994 | battery= 798.10 J
Episode  180/200 | steps=20141 | return=  -19.883 | avg_return(10)=  -21.112 | battery= 689.42 J
Episode  190/200 | steps=20163 | return=  -18.631 | avg_return(10)=  -21.064 | battery= 534.20 J
Episode  200/200 | steps=20065 | return=  -21.129 | avg_return(10)=  -20.722 | battery= 732.69 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 2
Total episodes: 200
Final episode return: -21.129
Avg return (last 10): -20.722
Best episode return: -17.110
================================================================================

✅ Saved actor to results/scenarios/s1_class2_90/actor.pt
✅ Saved critic to results/scenarios/s1_class2_90/critic.pt

[s1_class2_90] ✓ RL training complete


================================================================================
[s1_class2_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 2
================================================================================
Loading model from: results/scenarios/s1_class2_90

✅ Loaded trained actor from results/scenarios/s1_class2_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class2_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000399
Mean Latency: 0.014408 s
Mean Energy: 0.190 J
Final Battery: 3598.76 J
Success Rate: 99.7%
Offload Ratio: 0.993
================================================================================

[s1_class2_90] ✓ RL evaluation complete
  Mean QoE: -0.000399
  Final Battery: 3598.76 J
  Success Rate: 99.7%

[s1_class2_90] Time elapsed: 227.4 minutes


################################################################################
# SCENARIO 3/4: s1_class3_90
################################################################################

Name: Scenario 1 - 90% Class 3
Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
Task distribution: Class1=5%, Class2=5%, Class3=90%


================================================================================
[s1_class3_90] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_class3_90
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_class3_90...

✅ Saved LOCAL results to results/scenarios/s1_class3_90/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.096367
Mean Latency: 0.031147 s
Mean Energy: 1.993 J
Final Battery: 0.00 J
Success Rate: 6.5%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_class3_90/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025006
Mean Latency: 1.384878 s
Mean Energy: 0.023 J
Final Battery: 3754.91 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_class3_90/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.002608
Mean Latency: 0.041824 s
Mean Energy: 0.030 J
Final Battery: 3740.06 J
Success Rate: 97.4%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)

✅ Saved RANDOM results to results/scenarios/s1_class3_90/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.083340
Mean Latency: 0.036869 s
Mean Energy: 1.984 J
Final Battery: 0.00 J
Success Rate: 19.6%
Offload Ratio: 0.135
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_class3_90...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_class3_90/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.033606
Mean Latency: 1.382823 s
Mean Energy: 0.376 J
Final Battery: 3048.59 J
Success Rate: 66.4%
Offload Ratio: 0.885
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.096367            0.00 J           6.5%
mec                -0.025006         3754.91 J          75.0%
cloud              -0.002608         3740.06 J          97.4%
random             -0.083340            0.00 J          19.6%
greedy_by_size     -0.033606         3048.59 J          66.4%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_class3_90/
================================================================================

[s1_class3_90] ✓ Baselines complete


================================================================================
[s1_class3_90] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - 90% Class 3
================================================================================
Description: MEC unavailable 500-750, 1250-1500; 90% insensitive tasks
Task Distribution: Class1=5.0%, Class2=5.0%, Class3=90.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps=  672 | return=   -7.850 | avg_return(10)=   -7.850 | battery=   0.00 J
Episode   10/200 | steps= 7955 | return=  -15.955 | avg_return(10)=  -20.359 | battery=   0.00 J
Episode   20/200 | steps= 8712 | return=  -14.431 | avg_return(10)=  -17.601 | battery=   0.00 J
Episode   30/200 | steps=10445 | return=  -59.230 | avg_return(10)=  -30.615 | battery=   0.00 J
Episode   40/200 | steps=11200 | return=  -21.365 | avg_return(10)=  -18.916 | battery=   0.00 J
Episode   50/200 | steps=17870 | return=  -28.629 | avg_return(10)=  -23.923 | battery=   0.00 J
Episode   60/200 | steps=17033 | return=  -26.843 | avg_return(10)=  -24.824 | battery=   0.00 J
Episode   70/200 | steps=19695 | return=  -27.390 | avg_return(10)=  -29.810 | battery=   0.00 J
Episode   80/200 | steps=12291 | return=  -17.962 | avg_return(10)=  -22.497 | battery=   0.00 J
Episode   90/200 | steps= 9628 | return=  -15.899 | avg_return(10)=  -20.952 | battery=   0.00 J
Episode  100/200 | steps= 9415 | return=  -21.242 | avg_return(10)=  -20.057 | battery=   0.00 J
Episode  110/200 | steps=11042 | return=  -25.158 | avg_return(10)=  -20.718 | battery=   0.00 J
Episode  120/200 | steps=10473 | return=  -13.541 | avg_return(10)=  -20.488 | battery=   0.00 J
Episode  130/200 | steps=10790 | return=  -19.013 | avg_return(10)=  -17.873 | battery=   0.00 J
Episode  140/200 | steps= 9830 | return=  -21.483 | avg_return(10)=  -20.840 | battery=   0.00 J
Episode  150/200 | steps=10550 | return=  -14.647 | avg_return(10)=  -24.022 | battery=   0.00 J
Episode  160/200 | steps= 8502 | return=  -19.898 | avg_return(10)=  -21.676 | battery=   0.00 J
Episode  170/200 | steps=10151 | return=  -17.925 | avg_return(10)=  -19.376 | battery=   0.00 J
Episode  180/200 | steps=10398 | return=  -13.910 | avg_return(10)=  -23.028 | battery=   0.00 J
Episode  190/200 | steps= 8737 | return=  -18.908 | avg_return(10)=  -19.202 | battery=   0.00 J
Episode  200/200 | steps= 9855 | return=  -13.787 | avg_return(10)=  -18.844 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - 90% Class 3
Total episodes: 200
Final episode return: -13.787
Avg return (last 10): -18.844
Best episode return: -7.850
================================================================================

✅ Saved actor to results/scenarios/s1_class3_90/actor.pt
✅ Saved critic to results/scenarios/s1_class3_90/critic.pt

[s1_class3_90] ✓ RL training complete


================================================================================
[s1_class3_90] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - 90% Class 3
================================================================================
Loading model from: results/scenarios/s1_class3_90

✅ Loaded trained actor from results/scenarios/s1_class3_90/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_class3_90/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000925
Mean Latency: 0.065713 s
Mean Energy: 1.533 J
Final Battery: 914.14 J
Success Rate: 99.8%
Offload Ratio: 0.952
================================================================================

[s1_class3_90] ✓ RL evaluation complete
  Mean QoE: -0.000925
  Final Battery: 914.14 J
  Success Rate: 99.8%

[s1_class3_90] Time elapsed: 126.2 minutes


################################################################################
# SCENARIO 4/4: s1_random
################################################################################

Name: Scenario 1 - Random Distribution
Description: MEC unavailable 500-750, 1250-1500; equal task distribution
Task distribution: Class1=33%, Class2=34%, Class3=33%


================================================================================
[s1_random] Running Baseline Policies
================================================================================


================================================================================
RUNNING ALL BASELINES ON: s1_random
================================================================================


################################################################################
# Running LOCAL policy
################################################################################

Running LOCAL policy on s1_random...
  Progress: 200/2000 (10.0%)

✅ Saved LOCAL results to results/scenarios/s1_random/local_metrics.csv

================================================================================
LOCAL POLICY SUMMARY
================================================================================
Mean QoE: -0.097045
Mean Latency: 0.031035 s
Mean Energy: 1.986 J
Final Battery: 0.00 J
Success Rate: 5.5%
Offload Ratio: 0.000
================================================================================


################################################################################
# Running MEC policy
################################################################################

Running MEC policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved MEC results to results/scenarios/s1_random/mec_metrics.csv

================================================================================
MEC POLICY SUMMARY
================================================================================
Mean QoE: -0.025003
Mean Latency: 0.543255 s
Mean Energy: 0.010 J
Final Battery: 3779.95 J
Success Rate: 75.0%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running CLOUD policy
################################################################################

Running CLOUD policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved CLOUD results to results/scenarios/s1_random/cloud_metrics.csv

================================================================================
CLOUD POLICY SUMMARY
================================================================================
Mean QoE: -0.016703
Mean Latency: 0.024005 s
Mean Energy: 0.013 J
Final Battery: 3773.63 J
Success Rate: 83.3%
Offload Ratio: 1.000
================================================================================


################################################################################
# Running RANDOM policy
################################################################################

Running RANDOM policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)

✅ Saved RANDOM results to results/scenarios/s1_random/random_metrics.csv

================================================================================
RANDOM POLICY SUMMARY
================================================================================
Mean QoE: -0.072210
Mean Latency: 0.147488 s
Mean Energy: 1.954 J
Final Battery: 0.00 J
Success Rate: 30.0%
Offload Ratio: 0.324
================================================================================


################################################################################
# Running GREEDY_BY_SIZE policy
################################################################################

Running GREEDY_BY_SIZE policy on s1_random...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)

✅ Saved GREEDY_BY_SIZE results to results/scenarios/s1_random/greedy_by_size_metrics.csv

================================================================================
GREEDY_BY_SIZE POLICY SUMMARY
================================================================================
Mean QoE: -0.078022
Mean Latency: 0.535141 s
Mean Energy: 1.909 J
Final Battery: 0.00 J
Success Rate: 22.0%
Offload Ratio: 0.303
================================================================================


================================================================================
BASELINE COMPARISON SUMMARY
================================================================================
Policy              Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
local              -0.097045            0.00 J           5.5%
mec                -0.025003         3779.95 J          75.0%
cloud              -0.016703         3773.63 J          83.3%
random             -0.072210            0.00 J          30.0%
greedy_by_size     -0.078022            0.00 J          22.0%
--------------------------------------------------------------------------------

✅ All baseline results saved to: results/scenarios/s1_random/
================================================================================

[s1_random] ✓ Baselines complete


================================================================================
[s1_random] Training RL Agent
================================================================================


============================================================
GPU DIAGNOSTICS
============================================================
PyTorch version: 2.9.0
CUDA available: True
CUDA version: 12.6
cuDNN version: 90501
Number of GPUs: 1

GPU 0: NVIDIA H100 80GB HBM3
  Memory allocated: 0.07 GB
  Memory reserved: 0.07 GB
  Max memory allocated: 0.07 GB

Current CUDA device: 0
CUDA_VISIBLE_DEVICES: 0
============================================================


[train_rl_on_scenario] Using device: cuda

================================================================================
TRAINING ON SCENARIO: Scenario 1 - Random Distribution
================================================================================
Description: MEC unavailable 500-750, 1250-1500; equal task distribution
Task Distribution: Class1=33.0%, Class2=34.0%, Class3=33.0%
Total timesteps: 2000
Training episodes: 200
================================================================================

State dimension: 13
Action space: 3 (local, MEC, cloud)

Actor device: cuda:0
Critic device: cuda:0

Starting training...

Episode    1/200 | steps= 8854 | return= -118.907 | avg_return(10)= -118.907 | battery=   0.00 J
Episode   10/200 | steps=17685 | return= -112.038 | avg_return(10)= -112.261 | battery=   0.00 J
Episode   20/200 | steps=13162 | return=  -70.226 | avg_return(10)=  -80.809 | battery=   0.00 J
Episode   30/200 | steps=18684 | return= -102.087 | avg_return(10)=  -96.261 | battery=   0.00 J
Episode   40/200 | steps=14373 | return=  -97.071 | avg_return(10)=  -95.180 | battery=   0.00 J
Episode   50/200 | steps=16543 | return= -115.138 | avg_return(10)= -105.025 | battery=   0.00 J
Episode   60/200 | steps=12502 | return=  -59.248 | avg_return(10)= -100.667 | battery=   0.00 J
Episode   70/200 | steps=17009 | return= -104.090 | avg_return(10)= -103.008 | battery=   0.00 J
Episode   80/200 | steps=17733 | return= -107.481 | avg_return(10)= -100.298 | battery=   0.00 J
Episode   90/200 | steps=16519 | return= -107.239 | avg_return(10)= -108.755 | battery=   0.00 J
Episode  100/200 | steps=15490 | return= -107.965 | avg_return(10)= -102.878 | battery=   0.00 J
Episode  110/200 | steps=18295 | return= -108.129 | avg_return(10)= -103.189 | battery=   0.00 J
Episode  120/200 | steps=15400 | return= -101.886 | avg_return(10)= -103.197 | battery=   0.00 J
Episode  130/200 | steps=20052 | return= -105.925 | avg_return(10)= -101.041 | battery=   3.11 J
Episode  140/200 | steps=14260 | return=  -89.567 | avg_return(10)=  -98.457 | battery=   0.00 J
Episode  150/200 | steps=18553 | return= -107.029 | avg_return(10)= -104.800 | battery=   0.00 J
Episode  160/200 | steps=17608 | return= -101.669 | avg_return(10)= -108.208 | battery=   0.00 J
Episode  170/200 | steps=17798 | return= -108.516 | avg_return(10)= -107.849 | battery=   0.00 J
Episode  180/200 | steps=16101 | return= -102.820 | avg_return(10)= -120.081 | battery=   0.00 J
Episode  190/200 | steps=14657 | return=  -98.076 | avg_return(10)=  -86.952 | battery=   0.00 J
Episode  200/200 | steps=14828 | return= -104.695 | avg_return(10)= -101.810 | battery=   0.00 J

================================================================================
TRAINING SUMMARY
================================================================================
Scenario: Scenario 1 - Random Distribution
Total episodes: 200
Final episode return: -104.695
Avg return (last 10): -101.810
Best episode return: -55.999
================================================================================

✅ Saved actor to results/scenarios/s1_random/actor.pt
✅ Saved critic to results/scenarios/s1_random/critic.pt

[s1_random] ✓ RL training complete


================================================================================
[s1_random] Evaluating RL Agent
================================================================================


================================================================================
EVALUATING RL AGENT ON: Scenario 1 - Random Distribution
================================================================================
Loading model from: results/scenarios/s1_random

✅ Loaded trained actor from results/scenarios/s1_random/actor.pt

Running evaluation...
  Progress: 200/2000 (10.0%)
  Progress: 400/2000 (20.0%)
  Progress: 600/2000 (30.0%)
  Progress: 800/2000 (40.0%)
  Progress: 1000/2000 (50.0%)
  Progress: 1200/2000 (60.0%)
  Progress: 1400/2000 (70.0%)
  Progress: 1600/2000 (80.0%)
  Progress: 1800/2000 (90.0%)
  Progress: 2000/2000 (100.0%)

✅ Saved evaluation results to results/scenarios/s1_random/rl_agent_metrics.csv

================================================================================
EVALUATION SUMMARY
================================================================================
Mean QoE: -0.000986
Mean Latency: 0.031871 s
Mean Energy: 0.756 J
Final Battery: 2467.10 J
Success Rate: 99.2%
Offload Ratio: 0.976
================================================================================

[s1_random] ✓ RL evaluation complete
  Mean QoE: -0.000986
  Final Battery: 2467.10 J
  Success Rate: 99.2%

[s1_random] Time elapsed: 191.4 minutes


================================================================================
GENERATING PLOTS
================================================================================

Generating Scenario 1 complete figure...

Plotting Class 1 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

Plotting Class 2 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

Plotting Class 3 (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

Plotting Random (90% tasks)...
Loaded RL results: 2000 timesteps
Loaded local results: 2000 timesteps
Loaded mec results: 2000 timesteps
Loaded cloud results: 2000 timesteps
Loaded random results: 2000 timesteps
Loaded greedy_by_size results: 2000 timesteps

✅ Figure saved to: results/scenarios/scenario_1_complete_figure.png
✓ Scenario 1 plots generated


================================================================================
ALL SCENARIOS COMPLETE
================================================================================
Total time: 775.4 minutes

RL Agent Results Summary:
--------------------------------------------------------------------------------
Scenario                 Mean QoE   Final Battery    Success Rate
--------------------------------------------------------------------------------
s1_class1_90            -0.000746         3625.32 J          99.3%
s1_class2_90            -0.000399         3598.76 J          99.7%
s1_class3_90            -0.000925          914.14 J          99.8%
s1_random               -0.000986         2467.10 J          99.2%
--------------------------------------------------------------------------------

Results saved to: /project/6083487/yuvraj/dynamic_offloading_using_deep_RL/results/scenarios/
================================================================================


End time: Sat Dec 20 01:10:12 EST 2025

=====================================
 Job Finished
=====================================
